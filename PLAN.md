# 食品工业B端意图识别系统优化方案

**版本**: v2.0
**日期**: 2026-01-26
**状态**: 待确认

---

## 一、执行摘要

本方案旨在将意图识别系统的准确率从当前的 **79-81%** 提升至 **92%+**，多意图识别率从 **33%** 提升至 **85%+**。

**核心发现**：系统中已存在大量可用组件（多意图分类器、查询分割器、混淆对处理器），但因为一个关键配置错误（`embedding.mode=noop`）导致这些组件全部被禁用。问题的根源不在于缺少功能，而在于**选错了模型类型**——GTE-base-zh 是检索模型，不是分类模型。

**解决方案**：更换为专用的中文分类模型 `chinese-roberta-wwm-ext`，修复训练脚本，重新训练分类器，激活现有的多意图处理流程。

---

## 二、现状诊断

### 2.1 当前性能指标

| 指标 | 当前值 | 目标值 | 差距 |
|------|--------|--------|------|
| 整体准确率 | 79-81% | 92%+ | -11% |
| 多意图识别率 | 33% | 85%+ | -52% |
| 生产类意图准确率 | 62% | 90%+ | -28% |
| 低置信度查询比例 | 约 25% | <10% | -15% |

### 2.2 根因分析

#### 问题一：模型选型错误（影响度 35%）

**现象**：系统配置 `embedding.mode=noop`，语义匹配功能被完全禁用。

**历史**：v12.9 版本测试时，发现启用 GTE-base-zh 语义匹配后准确率从 88% 下降到 78%，团队选择禁用语义功能，回退到纯短语匹配。

**根本原因**：GTE-base-zh 是**检索模型（Retrieval Model）**，其设计目标是计算文本相似度和向量搜索，而非文本分类。用检索模型做分类任务，相当于用搜索引擎做判断题，本质上是工具选型错误。

**类比解释**：
- 检索模型：「这两句话有多相似？」→ 输出一个 0-1 的相似度分数
- 分类模型：「这句话属于哪个类别？」→ 输出每个类别的概率分布

用检索模型做分类，需要先计算用户输入与 123 个意图的相似度，然后取最高的那个。这种间接方式效率低、准确率差。

#### 问题二：多意图代码被禁用（影响度 25%）

**现象**：`MultiLabelIntentClassifierImpl.java` 已完整实现 Sigmoid 多标签分类，但从未被执行。

**代码路径**：
```
用户输入 → containsMultiIntentTrigger() 检测到触发词
         → multiLabelIntentClassifier.isAvailable() 返回 false
         → 多意图分支被跳过
         → 降级为单意图识别
```

**原因**：`isAvailable()` 方法检查 `embeddingClient.isAvailable()`，而 `NoOpEmbeddingClient.isAvailable()` 硬编码返回 `false`。这意味着，只要 embedding 服务被禁用，所有依赖它的功能都被连带禁用。

**已存在的多意图组件**：
- `IntentPreprocessor.splitMultiIntent()`：根据分隔词拆分多意图查询
- `MultiIntentResult` DTO：完整的多意图结果数据结构
- `ExecutionStrategy` 枚举：顺序执行、并行执行、合并执行
- 触发词检测逻辑：「顺便」「另外」「还有」「同时」等

这些代码都已写好，只是被一个 `false` 挡在门外。

#### 问题三：训练脚本存在 Bug（影响度 20%）

**现象**：训练日志显示 `learning_rate: 0.0`，`grad_norm: NaN`，训练 5 轮后准确率仅 0.4%。

**原因**：`warmup_steps=100` 配置在小数据集上导致问题。Warmup 机制是让学习率从 0 逐渐升高到目标值，但如果 warmup 步数接近或超过总训练步数，学习率就永远停留在接近 0 的位置，模型无法学习。

**训练数据现状**：
- 已有 74,550 条训练数据
- 123 个意图类别
- 多种数据增强（回译、同义替换、动词变换）
- 标签映射文件完整

数据是充足的，但训练脚本的配置错误导致模型根本没有学习。

#### 问题四：短语库覆盖率不足（影响度 15%）

**现象**：短语精确匹配仅覆盖约 500 个固定表达，面对口语化、方言化表达无能为力。

**示例**：
| 短语库中有 | 用户实际说 | 结果 |
|------------|------------|------|
| 查看今日产量 | 今天产了多少 | 匹配失败 |
| 设备状态查询 | 设备怎么样了 | 匹配失败 |
| 库存盘点 | 还剩多少货 | 匹配失败 |

由于语义匹配被禁用，系统完全依赖短语精确匹配，一旦用户换个说法，就无法识别。

#### 问题五：意图边界模糊（影响度 5%）

**现象**：部分意图定义存在语义重叠，导致混淆。

**混淆对示例**：
| 意图 A | 意图 B | 混淆原因 |
|--------|--------|----------|
| PROCESSING_BATCH_LIST | PROCESSING_BATCH_TIMELINE | 都涉及「批次」，列表 vs 时间线 |
| MATERIAL_EXPIRING_ALERT | MATERIAL_EXPIRED_QUERY | 「临期」vs「过期」一字之差 |
| PRODUCTION_OUTPUT | PRODUCTION_PLAN | 「产量」vs「计划」容易混淆 |

现有的 `ArenaRLConfig.java` 已定义了部分混淆对，但覆盖不完整。

### 2.3 已有组件清单

以下组件**已经存在**，只需激活或修复：

| 组件 | 文件位置 | 完成度 | 状态 |
|------|----------|--------|------|
| 多标签分类器 | `MultiLabelIntentClassifierImpl.java` | 100% | 被禁用 |
| 多意图分割器 | `IntentPreprocessor.splitMultiIntent()` | 100% | 可用 |
| 多意图结果 DTO | `MultiIntentResult.java` | 100% | 可用 |
| 执行策略枚举 | `ExecutionStrategy` | 100% | 可用 |
| 混淆对配置 | `ArenaRLConfig.java` | 60% | 需扩充 |
| 训练数据 | `merged_classification_train.json` | 74,550条 | 可用 |
| 标签映射 | `merged_labels.json` | 123个 | 可用 |
| Python 分类模块 | `python-services/modules/classifier/` | 80% | 未集成 |
| 微调脚本 | `finetune_classifier.py` | 90% | 有 Bug |

**结论**：问题不在于缺少代码，而在于配置错误和模型选型错误。

---

## 三、模型选型

### 3.1 当前模型问题

**GTE-base-zh** 是阿里达摩院发布的通用文本嵌入模型，专为以下任务设计：
- 语义相似度计算
- 向量检索/搜索
- RAG 系统中的文档召回

它**不是**分类模型，没有分类头（Classification Head），无法直接输出「这句话属于哪个意图」。

当前系统用它做分类的方式是：
1. 将用户输入转为 768 维向量
2. 将所有 123 个意图的描述也转为向量
3. 计算用户输入与每个意图的余弦相似度
4. 取相似度最高的意图作为结果

这种「曲线救国」的方式存在以下问题：
- 计算量大：每次请求需要计算 123 次相似度
- 区分度差：相似的意图（如「临期」和「过期」）向量也相似，难以区分
- 无法多标签：难以判断「哪些意图都适用」

### 3.2 推荐模型

基于服务器配置（7.3GB 内存，可能无独立 GPU）和任务需求，推荐以下模型：

| 模型 | 参数量 | 模型大小 | CPU 推理 | GPU 推理 | 适用场景 |
|------|--------|----------|----------|----------|----------|
| **hfl/chinese-roberta-wwm-ext** | 110M | ~400MB | ~200ms | ~20ms | 首选，综合最优 |
| hfl/rbt3 | ~38M | ~150MB | ~60ms | ~8ms | 备选，资源紧张时 |
| bert-base-chinese | 110M | ~400MB | ~200ms | ~20ms | 可用，但不如 RoBERTa |

**首选推荐**：`hfl/chinese-roberta-wwm-ext`

### 3.3 为什么选择 chinese-roberta-wwm-ext

**技术优势**：

1. **全词遮罩（Whole Word Masking）**
   普通 BERT 在预训练时随机遮罩字符，可能把「上海」拆成「上_」和「海」。RoBERTa-wwm 会把整个词「上海」一起遮罩，对中文分词更友好。

2. **更大的预训练数据**
   使用了维基百科、百度百科、新闻语料等多源数据，覆盖面更广。

3. **动态遮罩**
   BERT 在数据预处理时就固定了遮罩位置，RoBERTa 每次训练都随机生成新的遮罩，增加数据多样性。

4. **分类任务表现**
   在中文自然语言理解基准（CLUE）上，RoBERTa-wwm-ext 在文本分类任务上比 bert-base-chinese 高 2-3 个百分点。

**资源需求**：

| 场景 | 内存/显存 | 说明 |
|------|-----------|------|
| 推理（CPU） | ~1.5GB 内存 | 服务器 7.3GB 足够 |
| 推理（GPU） | ~1-2GB 显存 | 有 GPU 更快 |
| 训练 | ~3GB 显存 | 需要 GPU，batch_size=16 |

**备选方案**：如果服务器资源紧张或需要更快的响应速度，可使用 `hfl/rbt3`。这是 RoBERTa 的 3 层轻量版，参数量减少 65%，推理速度提升 3-4 倍，准确率下降约 3-5%。

### 3.4 模型对比总结

| 对比项 | GTE-base-zh（当前） | chinese-roberta-wwm-ext（推荐） |
|--------|---------------------|--------------------------------|
| 设计目标 | 语义相似度、检索 | 文本理解、分类 |
| 输出类型 | 768 维向量 | 分类概率分布 |
| 分类方式 | 间接（余弦相似度） | 直接（Softmax/Sigmoid） |
| 多标签支持 | 困难 | 原生支持 |
| 训练方式 | 对比学习 | 标准交叉熵 |
| 推理效率 | 需计算 123 次相似度 | 一次前向传播 |

---

## 四、执行计划

### Phase 0：快速验证（1-2 天）

**目标**：用最小改动验证方案可行性，确认现有代码路径正常

**方法**：临时启用 LLM API 作为分类后端，跳过 embedding 服务检查

**具体步骤**：

1. 修改 `MultiLabelIntentClassifierImpl.isAvailable()` 方法，临时返回 `true`
2. 在分类逻辑中，当 embedding 不可用时，调用现有的 LLM fallback 服务
3. 运行多意图测试用例，观察代码路径是否正常触发

**预期效果**：
- 确认 `AIIntentServiceImpl.java:1056` 的多意图分支能够执行
- 识别可能的集成问题（参数传递、类型转换等）
- 多意图识别率临时提升至 50% 左右

**风险与限制**：
- LLM API 调用有成本，仅作为验证手段
- 响应速度较慢（~1-2 秒/请求）
- 不适合生产环境长期使用

**决策点**：此阶段可选，如果对现有代码有信心，可跳过直接进入 Phase 1。

---

### Phase 1：分类器训练与部署（5-7 天）

这是核心阶段，解决「模型选型错误」和「训练脚本 Bug」两个根本问题。

#### 1.1 修复训练脚本

**问题回顾**：`warmup_steps=100` 导致学习率始终为 0，模型无法学习。

**修复内容**：

| 参数 | 修复前 | 修复后 | 说明 |
|------|--------|--------|------|
| warmup 配置 | `warmup_steps=100` | `warmup_ratio=0.1` | 按比例预热，避免步数问题 |
| 学习率 | `5e-5` | `2e-5` | BERT 论文推荐值 |
| 调度器 | 未指定 | `linear` | 明确线性衰减 |
| 随机种子 | 未指定 | `42` | 固定种子便于复现 |
| 半精度 | 禁用 | 有 GPU 时启用 | 加速训练 |

#### 1.2 验证训练数据质量

**检查项**：

1. **标签分布**：检查 123 个意图的样本数分布，识别长尾问题
   - 如果某些意图样本少于 50 条，需要增强
   - 如果某些意图样本超过 5000 条，可能需要下采样

2. **标注一致性**：抽样 500-1000 条人工审核
   - 同一表达是否被标注为不同意图？
   - 标注是否符合业务定义？

3. **增强数据质量**：检查回译和同义替换是否引入噪声
   - 回译后语义是否变化？
   - 同义词替换是否合理？

**建议**：如果发现严重质量问题，优先修复数据，而非急于训练。

#### 1.3 训练分类模型

**训练配置**：

| 参数 | 值 | 说明 |
|------|-----|------|
| 基础模型 | `hfl/chinese-roberta-wwm-ext` | 从 Hugging Face 下载 |
| 训练数据 | 74,550 条 | `merged_classification_train.json` |
| 验证数据 | ~7,000 条 | `merged_classification_val.json` |
| 标签数量 | 123 个 | `merged_labels.json` |
| 训练轮次 | 5 epochs | 根据验证集表现可调整 |
| 学习率 | 2e-5 | 线性衰减 |
| 批次大小 | 16 | 根据 GPU 显存调整 |
| 最大长度 | 128 tokens | 覆盖 99% 的用户输入 |

**预期指标**：

| 指标 | 目标值 |
|------|--------|
| 训练集准确率 | 95%+ |
| 验证集准确率 | 88-90% |
| F1-macro | 85%+ |
| F1-weighted | 88%+ |

**训练环境**：
- 推荐使用 GPU（8GB+ 显存）
- 本地训练或使用云服务（AutoDL、恒源云等）
- 预计训练时间：GPU 约 2-3 小时，CPU 约 10+ 小时

#### 1.4 部署推理服务

**部署位置**：`python-services` 统一服务（端口 8083）

按照项目架构规范，所有 Python 服务部署在同一个进程中。分类器模块已在 `python-services/modules/classifier/` 创建，需要完成集成。

**服务接口**：

```
POST /api/classifier/classify
请求体：
{
  "text": "用户输入文本",
  "top_k": 3,          // 返回 top k 个意图
  "threshold": 0.5     // 置信度阈值
}

响应体：
{
  "success": true,
  "data": {
    "intents": [
      {"code": "PRODUCTION_OUTPUT", "confidence": 0.92},
      {"code": "INVENTORY_STATUS", "confidence": 0.78}
    ],
    "is_multi_intent": true,
    "processing_time_ms": 45
  }
}
```

**资源消耗预估**：

| 场景 | 资源 |
|------|------|
| 模型加载 | ~1.5GB 内存 |
| 单次推理（CPU） | ~150-200ms |
| 单次推理（GPU） | ~15-25ms |
| 并发能力（CPU） | ~5 QPS |
| 并发能力（GPU） | ~50 QPS |

#### 1.5 Java 端集成

**新增组件**：`ClassifierIntentMatcher.java`

**职责**：
1. 调用 Python 分类服务
2. 处理超时和异常
3. 将分类结果转换为现有的 `IntentMatchResult` 格式
4. 提供健康检查和降级能力

**配置更新**：

```properties
# 分类器模式：python-service（推荐）或 noop（禁用）
classifier.mode=python-service

# Python 分类服务地址
classifier.service.url=http://localhost:8083/api/classifier

# 请求超时（毫秒）
classifier.timeout=5000

# 降级策略：phrase（短语匹配）或 llm（LLM fallback）
classifier.fallback=phrase
```

**集成流程**：

```
用户输入
    ↓
ClassifierIntentMatcher.classify()
    ↓
Python 服务返回 top-k 意图
    ↓
转换为 IntentMatchResult
    ↓
后续流程（参数提取、SQL 生成等）
```

---

### Phase 2：多意图流程激活（2-3 天）

这个阶段几乎不需要写新代码，只需要确保 Phase 1 的分类器正确集成，现有代码就会自动激活。

#### 2.1 原理说明

当前代码已实现完整的多意图处理流程，被 `isAvailable()=false` 阻断。

**完整流程**：

```
Step 1: 用户输入「查一下今天产量，顺便看看库存」

Step 2: containsMultiIntentTrigger() 检测到「顺便」→ 返回 true

Step 3: multiLabelIntentClassifier.isAvailable() → 现在返回 true（分类器可用）

Step 4: classifyMultiLabel() 调用分类器
        → 返回 [PRODUCTION_OUTPUT: 0.92, INVENTORY_STATUS: 0.85]

Step 5: 构建 MultiIntentResult
        → isMultiIntent = true
        → intents = [PRODUCTION_OUTPUT, INVENTORY_STATUS]
        → strategy = SEQUENTIAL（顺序执行）

Step 6: 按顺序执行两个意图，聚合结果返回
```

#### 2.2 需要验证的代码路径

以下代码路径需要测试确认能够正常执行：

1. `AIIntentServiceImpl.java:1056-1070`：多意图前置检测分支
2. `AIIntentServiceImpl.java:1148-1175`：多意图处理分支
3. `MultiLabelIntentClassifierImpl.classifyMultiLabel()`：多标签分类逻辑
4. `IntentPreprocessor.splitMultiIntent()`：查询分割逻辑

#### 2.3 多意图触发词

系统已配置的触发词：

```java
// 强触发词（检测到即触发多意图检测）
"顺便", "另外", "还要", "再查", "再看", "同时还"

// 多意图分隔词（用于拆分查询）
"顺便", "另外", "还有", "同时", "然后", "接着", "以及", "并且", "还要", "再"
```

如需扩展，可以添加更多口语化表达。

#### 2.4 执行策略

`MultiIntentResult.ExecutionStrategy` 定义了三种策略：

| 策略 | 适用场景 | 示例 |
|------|----------|------|
| SEQUENTIAL | 有先后顺序 | 「先看产量，再看库存」 |
| PARALLEL | 可并行执行 | 「产量和库存都给我看看」 |
| MERGE | 合并为复合查询 | 「产量和库存的汇总报表」 |

当前默认使用 SEQUENTIAL，可根据业务需求调整。

---

### Phase 3：短语库扩充与混淆对优化（3-5 天）

#### 3.1 短语库扩充

**目标**：从 500 条扩充到 2000+ 条

**方法**：

1. **用户日志挖掘**
   分析历史查询日志，找出低置信度但高频的表达，人工标注后加入短语库。

2. **LLM 批量生成**
   对每个意图，用 Claude 生成 20-30 种口语化表达。

   提示词示例：
   ```
   意图：查询今日产量（PRODUCTION_OUTPUT）
   请生成 20 种不同的中文表达方式，包括：
   - 正式表达
   - 口语化表达
   - 简略表达
   - 方言化表达（普通话为主）
   ```

3. **方言/简称适配**
   添加常见的简称和口语：
   - 「看下」→「瞅瞅」「瞧瞧」
   - 「查询」→「查查」「找找」
   - 「统计」→「算算」「数数」

**格式示例**：

```
PRODUCTION_OUTPUT:
  - 今天产量
  - 今天产了多少
  - 今天的产量是多少
  - 今天出了多少货
  - 今天做了多少
  - 看下今天的产量
  - 今天产能怎么样
  ...
```

#### 3.2 混淆对优化

**当前已配置的混淆对**（`ArenaRLConfig.java`）：

| 意图 A | 意图 B | minGap |
|--------|--------|--------|
| PROCESSING_BATCH_LIST | PROCESSING_BATCH_TIMELINE | 0.20 |
| MATERIAL_EXPIRING_ALERT | MATERIAL_EXPIRED_QUERY | 0.25 |
| EQUIPMENT_STATUS | EQUIPMENT_MAINTENANCE | 0.20 |

**需要新增的混淆对**：

| 意图 A | 意图 B | 建议 minGap | 混淆原因 |
|--------|--------|-------------|----------|
| PRODUCTION_OUTPUT | PRODUCTION_PLAN | 0.25 | 「产量」vs「计划」 |
| QUALITY_CHECK_RESULT | QUALITY_CHECK_TASK | 0.20 | 「结果」vs「任务」 |
| INVENTORY_STATUS | INVENTORY_MOVEMENT | 0.20 | 「库存」vs「出入库」 |
| ATTENDANCE_DAILY | ATTENDANCE_STATS | 0.20 | 「今日」vs「统计」 |
| ORDER_LIST | ORDER_DETAIL | 0.15 | 「列表」vs「详情」 |

**混淆对处理机制**：

当两个意图的置信度差距小于 `minGap` 时：
1. 触发二次判别（使用更多上下文信息）
2. 或向用户确认（「您是想查产量还是生产计划？」）

#### 3.3 动态混淆发现服务

**新增服务**：`ConfusionDiscoveryService`

**功能**：
1. 定期（每天/每周）分析用户反馈数据
2. 统计哪些意图经常被用户纠正
3. 自动识别新的混淆对
4. 动态调整 `minGap` 阈值

**数据来源**：
- 用户点击「不是我想要的」的记录
- 用户重新提问的记录
- 低置信度查询日志

---

### Phase 4：食品行业专项优化（可选，5-7 天）

此阶段为可选优化，建议在 Phase 1-3 完成并验证效果后，根据实际需求决定是否实施。

#### 4.1 食品行业术语映射

**问题**：用户使用行业术语或简称，系统无法理解。

**术语词典示例**：

| 用户说 | 标准化为 | 说明 |
|--------|----------|------|
| 批号 | batch_number | 批次号 |
| 效期 | expiry_date | 有效期 |
| 车间 | workshop | 生产车间 |
| QC | quality_check | 质量检测 |
| 入库 | warehouse_in | 入库操作 |
| 出库 | warehouse_out | 出库操作 |
| 良品率 | yield_rate | 良品率 |
| 报废 | scrap | 报废处理 |

**处理方式**：在预处理阶段进行术语标准化，然后再进行意图分类。

#### 4.2 溯源场景优化

**特殊场景**：

1. **扫码查询**
   输入为批次号或溯源码（如 `B20260126001`），需要识别为溯源查询意图。

2. **时间范围查询**
   「上周的」「这个月」需要解析为具体日期范围。

3. **模糊查询**
   「最近的订单」需要理解为时间倒序排列。

#### 4.3 实施建议

此阶段的优先级较低，原因：
1. Phase 1-3 已经能解决大部分问题
2. 术语映射可以通过短语库部分覆盖
3. 需要更多业务领域知识

建议在 Phase 1-3 完成后，收集实际生产环境的问题案例，针对性优化。

---

## 五、资源需求

### 5.1 人力资源

| 阶段 | 工作量 | 技能要求 |
|------|--------|----------|
| Phase 0 | 0.5-1 人天 | Java 后端 |
| Phase 1 | 3-4 人天 | Python ML + Java 后端 |
| Phase 2 | 1-2 人天 | Java 后端 |
| Phase 3 | 2-3 人天 | 数据标注 + 后端 |
| Phase 4 | 3-5 人天 | 业务分析 + 后端 |

### 5.2 硬件资源

| 资源 | 需求 | 说明 |
|------|------|------|
| 训练 GPU | 8GB+ 显存 | RTX 3070/3080 或云 GPU |
| 推理服务器 | 7.3GB 内存（现有） | 足够 CPU 推理 |
| 模型存储 | ~500MB | 存放训练好的模型文件 |

### 5.3 外部服务

| 服务 | 用途 | 成本估算 |
|------|------|----------|
| Claude API | 短语库生成 | ~$10-20（一次性） |
| 云 GPU（可选） | 模型训练 | ~$5-10/小时 |

---

## 六、风险与缓解

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|----------|
| 训练数据质量差 | 中 | 高 | 人工抽样审核，发现问题先修数据 |
| 模型过拟合 | 中 | 中 | 早停、正则化、增加验证集监控 |
| Python 服务不稳定 | 低 | 高 | 健康检查、自动重启、降级到短语匹配 |
| 多意图误触发 | 中 | 中 | 调整触发词、提高置信度阈值 |
| 服务器资源不足 | 低 | 中 | 使用轻量模型 RBT3 作为备选 |

---

## 七、回滚方案

每个阶段都保留回滚能力：

| 阶段 | 回滚方法 | 回滚时间 |
|------|----------|----------|
| Phase 0 | 删除临时代码，恢复 `isAvailable()=false` | <5 分钟 |
| Phase 1 | 配置 `classifier.mode=noop`，回退到短语匹配 | <1 分钟 |
| Phase 2 | 禁用多意图检测条件 | <5 分钟 |
| Phase 3 | 使用旧版短语库配置 | <1 分钟 |

---

## 八、预期效果

### 8.1 分阶段目标

| 阶段 | 整体准确率 | 多意图识别 | 生产意图 | 累计工作量 |
|------|------------|------------|----------|------------|
| 当前 | 79-81% | 33% | 62% | - |
| Phase 0 完成 | 82-84% | 50% | 70% | 1 天 |
| Phase 1 完成 | 86-88% | 60% | 82% | 6-8 天 |
| Phase 2 完成 | 88-90% | 80% | 85% | 8-11 天 |
| Phase 3 完成 | 90-92% | 85% | 90% | 11-16 天 |

### 8.2 验收标准

**Phase 1 验收**：
- [ ] 分类器在验证集上 F1-macro >= 85%
- [ ] Python 服务响应时间 P99 < 500ms
- [ ] Java 集成测试通过率 100%
- [ ] 服务启动后内存占用 < 2GB

**Phase 2 验收**：
- [ ] 多意图测试用例通过率 >= 80%
- [ ] 单意图误判为多意图的比例 < 5%
- [ ] 多意图结果聚合正确

**Phase 3 验收**：
- [ ] 低置信度查询比例从 25% 下降到 15% 以下
- [ ] 混淆对二次判别准确率 >= 90%
- [ ] 短语库覆盖率提升 50%+

---

## 九、决策确认

请确认以下决策点：

1. **模型选择**
   是否使用推荐的 `hfl/chinese-roberta-wwm-ext`？
   □ 是，使用推荐模型
   □ 否，使用轻量版 `hfl/rbt3`
   □ 其他：___________

2. **训练环境**
   □ 本地 GPU 训练（需要 8GB+ 显存）
   □ 使用云 GPU 服务（AutoDL/恒源云等）
   □ 先用 CPU 尝试（速度慢但可行）

3. **Phase 0 执行**
   □ 执行快速验证（额外 1 天）
   □ 跳过，直接进入 Phase 1

4. **Phase 4 优先级**
   □ 纳入本次迭代
   □ 暂不纳入，Phase 1-3 完成后再评估

---

## 参考资源

- [Chinese-BERT-wwm GitHub - ymcui](https://github.com/ymcui/Chinese-BERT-wwm)
- [hfl/chinese-roberta-wwm-ext - Hugging Face](https://huggingface.co/hfl/chinese-roberta-wwm-ext)
- [RBT3 轻量级模型介绍](https://www.promptlayer.com/models/rbt3)
- [中文预训练模型对比 - CSDN](https://blog.csdn.net/gitblog_02814/article/details/144501283)
- [BERT 模型硬件要求 - 百度开发者](https://developer.baidu.com/article/details/1878187)
- [ModernBERT - Hugging Face Blog](https://huggingface.co/blog/modernbert)

#!/usr/bin/env python3
"""
AI Intent Recognition System - Comprehensive 500 Test Cases
Tests all 4 Phases:
- Phase 1: Preview/Confirm (TCC) for high-risk operations
- Phase 2: Multi-source confidence fusion (LLM, Keyword, Semantic)
- Phase 3: Smart clarification for ambiguous inputs
- Phase 4: Active learning triggers
"""

import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum
import random

# Configuration
BASE_URL = "http://139.196.165.140:10010"
LOGIN_URL = f"{BASE_URL}/api/mobile/auth/unified-login"
RECOGNIZE_URL = f"{BASE_URL}/api/public/ai-demo/recognize"
EXECUTE_URL = f"{BASE_URL}/api/public/ai-demo/execute"
ACTIVE_LEARNING_URL = f"{BASE_URL}/api/mobile/F001/ai/active-learning"

class TestCategory(Enum):
    SIMPLE_QUERY = "simple_query"           # Simple data queries
    COMPLEX_QUERY = "complex_query"         # Multi-condition queries
    HIGH_RISK_OP = "high_risk_operation"    # Delete/Update operations (Phase 1)
    AMBIGUOUS = "ambiguous"                 # Needs clarification (Phase 3)
    MULTI_INTENT = "multi_intent"           # Multiple intents in one input
    CONTEXT_DEPENDENT = "context_dependent" # Requires context/coreference
    LOW_CONFIDENCE = "low_confidence"       # Should trigger active learning (Phase 4)
    EDGE_CASE = "edge_case"                 # Edge cases and boundary tests
    DOMAIN_SPECIFIC = "domain_specific"     # Domain-specific terminology
    TYPO_NOISE = "typo_noise"               # Inputs with typos/noise

@dataclass
class TestCase:
    id: int
    category: TestCategory
    input_text: str
    expected_intent: str = None
    expected_behavior: str = None
    phase_tested: List[int] = None

    def to_dict(self):
        return {
            "id": self.id,
            "category": self.category.value,
            "input": self.input_text,
            "expected_intent": self.expected_intent,
            "expected_behavior": self.expected_behavior,
            "phases": self.phase_tested or []
        }

def generate_test_cases() -> List[TestCase]:
    """Generate 500 comprehensive test cases"""
    cases = []
    case_id = 1

    # ========== Category 1: Simple Queries (100 cases) ==========
    simple_queries = [
        ("æŸ¥çœ‹ä»Šå¤©çš„è®¢å•", "ORDER_QUERY", "direct_match"),
        ("æ˜¾ç¤ºæ‰€æœ‰äº§å“", "PRODUCT_TYPE_QUERY", "direct_match"),
        ("æŸ¥è¯¢åº“å­˜", "INVENTORY_QUERY", "direct_match"),
        ("ä»Šæ—¥ç”Ÿäº§æŠ¥è¡¨", "REPORT_PRODUCTION", "direct_match"),
        ("æŸ¥çœ‹å‘˜å·¥åˆ—è¡¨", "EMPLOYEE_QUERY", "direct_match"),
        ("æ˜¾ç¤ºè®¾å¤‡çŠ¶æ€", "EQUIPMENT_STATUS", "direct_match"),
        ("æŸ¥è¯¢æ‰¹æ¬¡ä¿¡æ¯", "BATCH_QUERY", "direct_match"),
        ("æŸ¥çœ‹è´¨æ£€è®°å½•", "QUALITY_RECORD_QUERY", "direct_match"),
        ("æ˜¾ç¤ºä»“åº“åˆ—è¡¨", "WAREHOUSE_QUERY", "direct_match"),
        ("æŸ¥è¯¢ä¾›åº”å•†", "SUPPLIER_QUERY", "direct_match"),
        ("ä»Šå¤©æœ‰å¤šå°‘è®¢å•", "ORDER_QUERY", "count_query"),
        ("äº§å“æœ‰å“ªäº›", "PRODUCT_TYPE_QUERY", "list_query"),
        ("åº“å­˜æƒ…å†µå¦‚ä½•", "INVENTORY_QUERY", "status_query"),
        ("ç”Ÿäº§è¿›åº¦æ€æ ·", "PRODUCTION_PROGRESS", "status_query"),
        ("è®¾å¤‡è¿è¡Œæ­£å¸¸å—", "EQUIPMENT_STATUS", "status_query"),
        ("æŸ¥ä¸€ä¸‹è®¢å•123", "ORDER_QUERY", "specific_query"),
        ("æ‰¾äº§å“PT001", "PRODUCT_TYPE_QUERY", "specific_query"),
        ("æ‰¹æ¬¡B001çš„ä¿¡æ¯", "BATCH_QUERY", "specific_query"),
        ("å‘˜å·¥å¼ ä¸‰çš„èµ„æ–™", "EMPLOYEE_QUERY", "specific_query"),
        ("ä»“åº“Açš„åº“å­˜", "INVENTORY_QUERY", "specific_query"),
        # English variations
        ("show orders", "ORDER_QUERY", "english_input"),
        ("list products", "PRODUCT_TYPE_QUERY", "english_input"),
        ("inventory status", "INVENTORY_QUERY", "english_input"),
        ("production report", "REPORT_PRODUCTION", "english_input"),
        ("employee list", "EMPLOYEE_QUERY", "english_input"),
        # Casual language
        ("è®¢å•å‘¢", "ORDER_QUERY", "casual"),
        ("äº§å“çœ‹çœ‹", "PRODUCT_TYPE_QUERY", "casual"),
        ("åº“å­˜å¤šå°‘", "INVENTORY_QUERY", "casual"),
        ("æŠ¥è¡¨ç»™æˆ‘", "REPORT_PRODUCTION", "casual"),
        ("å‘˜å·¥åå•", "EMPLOYEE_QUERY", "casual"),
        # With time context
        ("æ˜¨å¤©çš„è®¢å•", "ORDER_QUERY", "time_context"),
        ("ä¸Šå‘¨ç”Ÿäº§é‡", "REPORT_PRODUCTION", "time_context"),
        ("æœ¬æœˆåº“å­˜å˜åŒ–", "INVENTORY_QUERY", "time_context"),
        ("ä»Šå¹´é”€å”®é¢", "SALES_QUERY", "time_context"),
        ("è¿‡å»7å¤©çš„è´¨æ£€", "QUALITY_RECORD_QUERY", "time_context"),
        # With quantity
        ("å‰10ä¸ªè®¢å•", "ORDER_QUERY", "quantity_limit"),
        ("æœ€æ–°5ä¸ªäº§å“", "PRODUCT_TYPE_QUERY", "quantity_limit"),
        ("åº“å­˜æœ€ä½çš„10ä¸ª", "INVENTORY_QUERY", "quantity_limit"),
        ("é”€é‡å‰20", "SALES_QUERY", "quantity_limit"),
        ("æœ€è¿‘3ä¸ªæ‰¹æ¬¡", "BATCH_QUERY", "quantity_limit"),
    ]

    for i, (text, intent, behavior) in enumerate(simple_queries):
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.SIMPLE_QUERY,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[2]
        ))
        case_id += 1

    # Generate more simple query variations (to reach ~100)
    query_templates = [
        "æŸ¥çœ‹{entity}", "æ˜¾ç¤º{entity}", "æŸ¥è¯¢{entity}", "{entity}åˆ—è¡¨", "{entity}æƒ…å†µ",
        "è·å–{entity}", "æ‰¾{entity}", "{entity}æœ‰å“ªäº›", "{entity}æ˜¯ä»€ä¹ˆ", "çœ‹çœ‹{entity}"
    ]
    entities = ["è®¢å•", "äº§å“", "åº“å­˜", "å‘˜å·¥", "è®¾å¤‡", "æ‰¹æ¬¡", "ä»“åº“", "ä¾›åº”å•†", "å®¢æˆ·", "ç‰©æ–™"]

    for template in query_templates[:6]:
        for entity in entities[:6]:
            if case_id > 100:
                break
            cases.append(TestCase(
                id=case_id,
                category=TestCategory.SIMPLE_QUERY,
                input_text=template.format(entity=entity),
                expected_intent=None,
                expected_behavior="template_generated",
                phase_tested=[2]
            ))
            case_id += 1

    # ========== Category 2: Complex Queries (80 cases) ==========
    complex_queries = [
        ("æŸ¥è¯¢æœ¬æœˆé”€å”®é¢è¶…è¿‡10000çš„è®¢å•å¹¶æŒ‰é‡‘é¢æ’åº", "ORDER_QUERY", "multi_condition"),
        ("æ˜¾ç¤ºåº“å­˜ä½äºå®‰å…¨çº¿ä¸”éœ€è¦è¡¥è´§çš„äº§å“", "INVENTORY_QUERY", "multi_condition"),
        ("æ‰¾å‡ºè¿‡å»ä¸€å‘¨è´¨æ£€ä¸åˆæ ¼çš„æ‰¹æ¬¡åŠå…¶åŸå› ", "QUALITY_RECORD_QUERY", "multi_condition"),
        ("ç»Ÿè®¡å„ä»“åº“çš„åº“å­˜æ€»å€¼å¹¶ç”ŸæˆæŠ¥è¡¨", "REPORT_INVENTORY", "aggregation"),
        ("å¯¹æ¯”ä¸Šæœˆå’Œæœ¬æœˆçš„ç”Ÿäº§æ•ˆç‡", "REPORT_PRODUCTION", "comparison"),
        ("æŸ¥è¯¢å‘˜å·¥å¼ ä¸‰è´Ÿè´£çš„æ‰€æœ‰è®¢å•åŠå®Œæˆç‡", "ORDER_QUERY", "relation_query"),
        ("æ˜¾ç¤ºè®¾å¤‡Açš„ç»´æŠ¤è®°å½•å’Œä¸‹æ¬¡ä¿å…»æ—¶é—´", "EQUIPMENT_MAINTENANCE", "multi_field"),
        ("åˆ†æå®¢æˆ·è´­ä¹°è¡Œä¸ºå¹¶æ¨èç›¸ä¼¼äº§å“", "CUSTOMER_ANALYSIS", "analysis"),
        ("è®¡ç®—æ‰¹æ¬¡B001çš„æˆæœ¬æ„æˆ", "COST_ANALYSIS", "calculation"),
        ("é¢„æµ‹ä¸‹æœˆåº“å­˜éœ€æ±‚", "INVENTORY_FORECAST", "prediction"),
        # More complex queries
        ("æŸ¥è¯¢æ‰€æœ‰çŠ¶æ€ä¸ºå¾…å¤„ç†ä¸”åˆ›å»ºæ—¶é—´è¶…è¿‡3å¤©çš„è®¢å•", "ORDER_QUERY", "complex_filter"),
        ("æ‰¾å‡ºæœ¬å­£åº¦é”€é‡å¢é•¿è¶…è¿‡20%çš„äº§å“", "PRODUCT_TYPE_QUERY", "growth_analysis"),
        ("æ˜¾ç¤ºå„éƒ¨é—¨çš„äººå‘˜é…ç½®å’Œç»©æ•ˆå¯¹æ¯”", "EMPLOYEE_QUERY", "department_comparison"),
        ("åˆ†æè®¾å¤‡æ•…éšœç‡ä¸ç»´æŠ¤å‘¨æœŸçš„å…³ç³»", "EQUIPMENT_ANALYSIS", "correlation"),
        ("ç»Ÿè®¡å„ä¾›åº”å•†çš„äº¤ä»˜å‡†æ—¶ç‡", "SUPPLIER_ANALYSIS", "performance_metric"),
        # Time-series queries
        ("æ˜¾ç¤ºè¿‡å»12ä¸ªæœˆçš„é”€å”®è¶‹åŠ¿å›¾", "SALES_TREND", "time_series"),
        ("å¯¹æ¯”2024å’Œ2025å¹´åŒæœŸäº§é‡", "PRODUCTION_COMPARISON", "yoy_comparison"),
        ("åˆ†æåº“å­˜å‘¨è½¬ç‡çš„å­£åº¦å˜åŒ–", "INVENTORY_TURNOVER", "quarterly_analysis"),
        ("æŸ¥çœ‹è®¾å¤‡åˆ©ç”¨ç‡çš„æœˆåº¦æŠ¥å‘Š", "EQUIPMENT_UTILIZATION", "monthly_report"),
        ("ç»Ÿè®¡å®¢æˆ·æŠ•è¯‰çš„è¶‹åŠ¿å’Œåˆ†ç±»", "COMPLAINT_ANALYSIS", "trend_analysis"),
        # Multi-entity queries
        ("æŸ¥è¯¢è®¢å•O001å…³è”çš„æ‰€æœ‰æ‰¹æ¬¡å’Œç‰©æ–™", "ORDER_DETAIL", "multi_entity"),
        ("æ˜¾ç¤ºäº§å“P001çš„å®Œæ•´ä¾›åº”é“¾ä¿¡æ¯", "SUPPLY_CHAIN_QUERY", "chain_query"),
        ("æ‰¾å‡ºä¸å®¢æˆ·C001æœ‰å…³çš„æ‰€æœ‰äº¤æ˜“è®°å½•", "TRANSACTION_QUERY", "customer_related"),
        ("æŸ¥çœ‹å‘˜å·¥E001å‚ä¸çš„æ‰€æœ‰ç”Ÿäº§ä»»åŠ¡", "PRODUCTION_TASK_QUERY", "employee_related"),
        ("æ˜¾ç¤ºä»“åº“W001çš„å…¥åº“å‡ºåº“æ˜ç»†", "WAREHOUSE_TRANSACTION", "warehouse_detail"),
    ]

    for text, intent, behavior in complex_queries:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.COMPLEX_QUERY,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[2, 3]
        ))
        case_id += 1

    # Generate more complex queries
    complex_templates = [
        "æŸ¥è¯¢{time}çš„{entity}å¹¶æŒ‰{field}æ’åº",
        "ç»Ÿè®¡{entity}çš„{metric}å¹¶ç”Ÿæˆ{report_type}",
        "å¯¹æ¯”{time1}å’Œ{time2}çš„{metric}",
        "åˆ†æ{entity}çš„{behavior}è¶‹åŠ¿",
        "æ‰¾å‡º{condition}çš„{entity}åŠå…¶{detail}"
    ]

    time_options = ["æœ¬æœˆ", "ä¸Šå‘¨", "ä»Šå¹´", "æœ¬å­£åº¦", "è¿‡å»30å¤©"]
    entity_options = ["è®¢å•", "äº§å“", "åº“å­˜", "å‘˜å·¥", "è®¾å¤‡"]
    field_options = ["é‡‘é¢", "æ•°é‡", "æ—¶é—´", "çŠ¶æ€", "ç±»å‹"]

    for _ in range(55):
        if case_id > 180:
            break
        template = random.choice(complex_templates)
        text = template.format(
            time=random.choice(time_options),
            time1=random.choice(time_options),
            time2=random.choice(time_options),
            entity=random.choice(entity_options),
            field=random.choice(field_options),
            metric="æ•°é‡",
            report_type="æŠ¥è¡¨",
            behavior="å˜åŒ–",
            condition="å¼‚å¸¸",
            detail="è¯¦æƒ…"
        )
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.COMPLEX_QUERY,
            input_text=text,
            expected_intent=None,
            expected_behavior="template_generated",
            phase_tested=[2, 3]
        ))
        case_id += 1

    # ========== Category 3: High-Risk Operations - Phase 1 (60 cases) ==========
    high_risk_ops = [
        ("åˆ é™¤è®¢å•O001", "ORDER_DELETE", "delete_operation"),
        ("å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†è®¢å•", "ORDER_CANCEL_BATCH", "batch_delete"),
        ("æ¸…ç©ºåº“å­˜æ•°æ®", "INVENTORY_CLEAR", "dangerous_operation"),
        ("åˆ é™¤å‘˜å·¥E001çš„è®°å½•", "EMPLOYEE_DELETE", "delete_operation"),
        ("ç§»é™¤äº§å“P001", "PRODUCT_DELETE", "delete_operation"),
        ("åºŸå¼ƒæ‰¹æ¬¡B001", "BATCH_VOID", "void_operation"),
        ("åˆ é™¤æ‰€æœ‰è¿‡æœŸæ•°æ®", "DATA_PURGE", "batch_delete"),
        ("é‡ç½®ç³»ç»Ÿè®¾ç½®", "SYSTEM_RESET", "dangerous_operation"),
        ("æ¸…é™¤è´¨æ£€è®°å½•", "QUALITY_RECORD_DELETE", "delete_operation"),
        ("åˆ é™¤ä¾›åº”å•†S001", "SUPPLIER_DELETE", "delete_operation"),
        # Update operations that need confirmation
        ("ä¿®æ”¹æ‰€æœ‰è®¢å•çŠ¶æ€ä¸ºå·²å®Œæˆ", "ORDER_BATCH_UPDATE", "batch_update"),
        ("æ›´æ–°æ‰€æœ‰äº§å“ä»·æ ¼", "PRODUCT_PRICE_UPDATE", "batch_update"),
        ("æ‰¹é‡è°ƒæ•´åº“å­˜æ•°é‡", "INVENTORY_ADJUST", "batch_update"),
        ("ä¿®æ”¹å‘˜å·¥æƒé™", "EMPLOYEE_PERMISSION_UPDATE", "permission_change"),
        ("æ›´æ”¹ç³»ç»Ÿé…ç½®", "SYSTEM_CONFIG_UPDATE", "config_change"),
        # Irreversible operations
        ("æ°¸ä¹…åˆ é™¤å®¢æˆ·C001çš„æ‰€æœ‰æ•°æ®", "CUSTOMER_DATA_PURGE", "irreversible"),
        ("å½’æ¡£å¹¶åˆ é™¤2023å¹´çš„è®¢å•", "ORDER_ARCHIVE_DELETE", "irreversible"),
        ("åˆå¹¶é‡å¤çš„äº§å“è®°å½•", "PRODUCT_MERGE", "data_merge"),
        ("è¿ç§»ä»“åº“æ•°æ®åˆ°æ–°ç³»ç»Ÿ", "DATA_MIGRATION", "migration"),
        ("å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬", "SYSTEM_ROLLBACK", "rollback"),
        # Financial operations
        ("è°ƒæ•´è®¢å•O001çš„é‡‘é¢ä¸º0", "ORDER_AMOUNT_ADJUST", "financial"),
        ("å–æ¶ˆå®¢æˆ·C001çš„æ‰€æœ‰æ¬ æ¬¾", "DEBT_CANCEL", "financial"),
        ("ä¿®æ”¹è´¢åŠ¡æŠ¥è¡¨æ•°æ®", "FINANCIAL_REPORT_UPDATE", "financial"),
        ("åˆ é™¤ä»˜æ¬¾è®°å½•", "PAYMENT_DELETE", "financial"),
        ("é‡æ–°è®¡ç®—æ‰€æœ‰è®¢å•æˆæœ¬", "COST_RECALCULATE", "financial"),
    ]

    for text, intent, behavior in high_risk_ops:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.HIGH_RISK_OP,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[1, 2]
        ))
        case_id += 1

    # Generate more high-risk variations
    delete_verbs = ["åˆ é™¤", "ç§»é™¤", "æ¸…é™¤", "åºŸå¼ƒ", "å–æ¶ˆ", "ä½œåºŸ"]
    update_verbs = ["ä¿®æ”¹", "æ›´æ–°", "è°ƒæ•´", "å˜æ›´", "æ‰¹é‡æ›´æ–°"]
    targets = ["è®¢å•", "äº§å“", "åº“å­˜", "å‘˜å·¥", "æ‰¹æ¬¡", "è®°å½•", "æ•°æ®"]

    for verb in delete_verbs:
        for target in targets[:5]:
            if case_id > 240:
                break
            cases.append(TestCase(
                id=case_id,
                category=TestCategory.HIGH_RISK_OP,
                input_text=f"{verb}{target}",
                expected_intent=None,
                expected_behavior="high_risk_generic",
                phase_tested=[1, 2]
            ))
            case_id += 1

    # ========== Category 4: Ambiguous Inputs - Phase 3 (70 cases) ==========
    ambiguous_inputs = [
        ("æŸ¥ä¸€ä¸‹", None, "incomplete_query"),
        ("åˆ é™¤", None, "incomplete_delete"),
        ("ä¿®æ”¹é‚£ä¸ª", None, "unclear_reference"),
        ("çœ‹çœ‹æ•°æ®", None, "vague_query"),
        ("å¤„ç†ä¸€ä¸‹", None, "unclear_action"),
        ("é‚£ä¸ªè®¢å•", None, "missing_identifier"),
        ("ä¸Šæ¬¡è¯´çš„", None, "context_dependent"),
        ("å¸®æˆ‘å¼„ä¸€ä¸‹", None, "unclear_request"),
        ("è¿™ä¸ªä¸å¯¹", None, "unclear_problem"),
        ("æ”¹æˆæ­£ç¡®çš„", None, "unclear_target"),
        # Pronoun references
        ("æŸ¥çœ‹å®ƒçš„è¯¦æƒ…", None, "pronoun_reference"),
        ("æŠŠå®ƒåˆ æ‰", None, "pronoun_delete"),
        ("ä¿®æ”¹è¿™ä¸ª", None, "demonstrative_reference"),
        ("é‚£ä¸ªæ€ä¹ˆæ ·äº†", None, "demonstrative_query"),
        ("ä»–è´Ÿè´£çš„è®¢å•", None, "person_reference"),
        # Partial information
        ("è®¢å•...", None, "incomplete_input"),
        ("æŸ¥è¯¢é‚£ä¸ªå§“å¼ çš„", None, "partial_name"),
        ("ä¸Šå‘¨çš„é‚£æ‰¹è´§", None, "vague_time_reference"),
        ("ä»·æ ¼æ¯”è¾ƒé«˜çš„", None, "relative_condition"),
        ("æœ€è¿‘çš„é‚£ä¸ª", None, "temporal_reference"),
        # Multiple interpretations
        ("çœ‹çœ‹è®¢å•å’Œäº§å“", None, "multi_entity_ambiguous"),
        ("åˆ é™¤æˆ–è€…å–æ¶ˆ", None, "action_ambiguous"),
        ("ä»Šå¤©æˆ–æ˜å¤©çš„", None, "time_ambiguous"),
        ("å¼ ä¸‰æˆ–æå››çš„", None, "person_ambiguous"),
        ("Aä»“åº“æˆ–Bä»“åº“", None, "location_ambiguous"),
        # Missing key parameters
        ("æŸ¥è¯¢è®¢å•çŠ¶æ€", None, "missing_order_id"),
        ("ä¿®æ”¹äº§å“ä»·æ ¼", None, "missing_product_id"),
        ("è°ƒæ•´åº“å­˜æ•°é‡", None, "missing_quantity"),
        ("åˆ†é…ä»»åŠ¡ç»™å‘˜å·¥", None, "missing_assignment"),
        ("è®¾ç½®æé†’", None, "missing_reminder_detail"),
        # Contradictory inputs
        ("åˆ é™¤ä½†ä¿ç•™è®°å½•", None, "contradictory"),
        ("å¢åŠ å¹¶å‡å°‘åº“å­˜", None, "contradictory"),
        ("å®Œæˆæœªå®Œæˆçš„", None, "paradox"),
        ("æŸ¥è¯¢ä¸å­˜åœ¨çš„", None, "impossible_query"),
        ("ä¿®æ”¹åªè¯»æ•°æ®", None, "permission_issue"),
    ]

    for text, intent, behavior in ambiguous_inputs:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.AMBIGUOUS,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[3]
        ))
        case_id += 1

    # Generate more ambiguous cases
    vague_queries = [
        "é‚£ä¸ª", "è¿™ä¸ª", "å®ƒ", "ä»–ä»¬", "ä¹‹å‰çš„", "åé¢çš„", "å…¶ä»–çš„",
        "æŸ¥ä¸€ä¸‹å§", "çœ‹çœ‹å‘¢", "æ€ä¹ˆæ ·", "å¦‚ä½•", "å’‹åŠ", "å¼„ä¸€ä¸‹"
    ]

    for vq in vague_queries:
        for _ in range(2):
            if case_id > 310:
                break
            cases.append(TestCase(
                id=case_id,
                category=TestCategory.AMBIGUOUS,
                input_text=f"{vq}{random.choice(['', 'çš„æ•°æ®', 'çš„æƒ…å†µ', ''])}",
                expected_intent=None,
                expected_behavior="vague_input",
                phase_tested=[3]
            ))
            case_id += 1

    # ========== Category 5: Multi-Intent (50 cases) ==========
    multi_intents = [
        ("æŸ¥çœ‹è®¢å•å¹¶å¯¼å‡ºæŠ¥è¡¨", ["ORDER_QUERY", "REPORT_EXPORT"], "query_and_export"),
        ("å…ˆæŸ¥åº“å­˜å†ä¸‹è®¢å•", ["INVENTORY_QUERY", "ORDER_CREATE"], "sequential"),
        ("åˆ é™¤æ—§æ•°æ®å¹¶å¤‡ä»½", ["DATA_DELETE", "DATA_BACKUP"], "delete_and_backup"),
        ("ç»Ÿè®¡é”€å”®é¢å’Œåˆ©æ¶¦", ["SALES_QUERY", "PROFIT_QUERY"], "multiple_metrics"),
        ("æŸ¥çœ‹å‘˜å·¥è€ƒå‹¤å’Œç»©æ•ˆ", ["ATTENDANCE_QUERY", "PERFORMANCE_QUERY"], "hr_queries"),
        ("æ›´æ–°åº“å­˜å¹¶é€šçŸ¥ä»“ç®¡", ["INVENTORY_UPDATE", "NOTIFICATION_SEND"], "update_and_notify"),
        ("æŸ¥è¯¢è®¢å•çŠ¶æ€å’Œç‰©æµä¿¡æ¯", ["ORDER_STATUS", "LOGISTICS_QUERY"], "order_tracking"),
        ("ç”ŸæˆæŠ¥è¡¨å¹¶å‘é€é‚®ä»¶", ["REPORT_GENERATE", "EMAIL_SEND"], "report_and_send"),
        ("æ£€æŸ¥è®¾å¤‡çŠ¶æ€å¹¶å®‰æ’ç»´æŠ¤", ["EQUIPMENT_CHECK", "MAINTENANCE_SCHEDULE"], "check_and_schedule"),
        ("å®¡æ ¸è®¢å•å¹¶å®‰æ’å‘è´§", ["ORDER_REVIEW", "SHIPPING_ARRANGE"], "review_and_ship"),
        # Complex multi-intents
        ("æŸ¥è¯¢æœ¬æœˆè®¢å•ã€ç»Ÿè®¡é”€å”®é¢ã€å¹¶ç”ŸæˆæŠ¥è¡¨å‘ç»™ç»ç†", ["ORDER_QUERY", "SALES_STAT", "REPORT_SEND"], "triple_intent"),
        ("æ£€æŸ¥åº“å­˜ã€è¡¥è´§ã€å¹¶æ›´æ–°ä¾›åº”å•†ä¿¡æ¯", ["INVENTORY_CHECK", "REORDER", "SUPPLIER_UPDATE"], "supply_chain"),
        ("å‘˜å·¥å…¥èŒï¼šåˆ›å»ºè´¦å·ã€åˆ†é…æƒé™ã€å‘é€æ¬¢è¿é‚®ä»¶", ["ACCOUNT_CREATE", "PERMISSION_ASSIGN", "EMAIL_SEND"], "onboarding"),
        ("æœˆæœ«ç»“ç®—ï¼šæ ¸å¯¹è´¦ç›®ã€ç”ŸæˆæŠ¥è¡¨ã€å½’æ¡£æ•°æ®", ["ACCOUNT_VERIFY", "REPORT_GENERATE", "DATA_ARCHIVE"], "month_end"),
        ("è´¨é‡é—®é¢˜å¤„ç†ï¼šè®°å½•é—®é¢˜ã€é€šçŸ¥ç›¸å…³äººã€å®‰æ’å¤æ£€", ["QUALITY_RECORD", "NOTIFICATION", "RECHECK_SCHEDULE"], "quality_flow"),
    ]

    for text, intents, behavior in multi_intents:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.MULTI_INTENT,
            input_text=text,
            expected_intent=str(intents),
            expected_behavior=behavior,
            phase_tested=[2, 3]
        ))
        case_id += 1

    # Generate more multi-intent cases
    action_pairs = [
        ("æŸ¥çœ‹", "ä¿®æ”¹"), ("æŸ¥è¯¢", "å¯¼å‡º"), ("ç»Ÿè®¡", "åˆ†æ"),
        ("æ£€æŸ¥", "æ›´æ–°"), ("å®¡æ ¸", "é€šçŸ¥"), ("åˆ›å»º", "åˆ†é…")
    ]

    for a1, a2 in action_pairs:
        for entity in entities[:5]:
            if case_id > 360:
                break
            cases.append(TestCase(
                id=case_id,
                category=TestCategory.MULTI_INTENT,
                input_text=f"{a1}{entity}å¹¶{a2}",
                expected_intent=None,
                expected_behavior="action_pair",
                phase_tested=[2, 3]
            ))
            case_id += 1

    # ========== Category 6: Context-Dependent (40 cases) ==========
    context_cases = [
        ("ä¸Šé¢é‚£ä¸ªè®¢å•çš„è¯¦æƒ…", None, "previous_reference"),
        ("åˆšæ‰æŸ¥çš„é‚£æ‰¹è´§", None, "recent_reference"),
        ("åŒæ ·çš„æŸ¥è¯¢æ¡ä»¶", None, "same_condition"),
        ("å’Œä¹‹å‰ä¸€æ ·", None, "repeat_action"),
        ("ç»§ç»­åˆšæ‰çš„æ“ä½œ", None, "continue_action"),
        ("æ’¤é”€ä¸Šä¸€æ­¥", None, "undo_action"),
        ("å†æŸ¥ä¸€æ¬¡", None, "repeat_query"),
        ("æ¢ä¸€ä¸ªæ¡ä»¶", None, "modify_condition"),
        ("çœ‹çœ‹åˆ«çš„", None, "alternative_query"),
        ("è¿™ä¸ªä¸è¡Œ,æ¢é‚£ä¸ª", None, "switch_target"),
        # Session context
        ("åŸºäºè¿™ä¸ªç»“æœç­›é€‰", None, "filter_result"),
        ("åœ¨è¿™äº›é‡Œé¢æ‰¾", None, "search_in_result"),
        ("æ’é™¤æ‰å·²é€‰çš„", None, "exclude_selected"),
        ("åªä¿ç•™ç¬¦åˆæ¡ä»¶çš„", None, "filter_keep"),
        ("æŠŠè¿™äº›åˆå¹¶", None, "merge_result"),
        # Conversation flow
        ("ç„¶åå‘¢", None, "continue_conversation"),
        ("è¿˜æœ‰å—", None, "more_results"),
        ("å°±è¿™æ ·", None, "confirm_action"),
        ("ä¸å¯¹,æ˜¯å¦ä¸€ä¸ª", None, "correct_input"),
        ("æˆ‘æ˜¯è¯´é‚£ä¸ª", None, "clarify_reference"),
    ]

    for text, intent, behavior in context_cases:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.CONTEXT_DEPENDENT,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[3]
        ))
        case_id += 1

    # More context-dependent cases
    context_words = ["åˆšæ‰", "ä¸Šæ¬¡", "ä¹‹å‰", "é‚£ä¸ª", "è¿™ä¸ª", "åŒæ ·", "ä¸€æ ·", "ç»§ç»­"]
    for word in context_words:
        for _ in range(2):
            if case_id > 400:
                break
            cases.append(TestCase(
                id=case_id,
                category=TestCategory.CONTEXT_DEPENDENT,
                input_text=f"{word}çš„{random.choice(['è®¢å•', 'äº§å“', 'æ•°æ®', 'ç»“æœ', 'æ“ä½œ'])}",
                expected_intent=None,
                expected_behavior="context_word",
                phase_tested=[3]
            ))
            case_id += 1

    # ========== Category 7: Low Confidence / Edge Cases - Phase 4 (50 cases) ==========
    low_confidence_cases = [
        ("xjklsdf", None, "gibberish"),
        ("123456", None, "numbers_only"),
        ("???", None, "punctuation_only"),
        ("", None, "empty_input"),
        (" ", None, "whitespace_only"),
        ("a", None, "single_char"),
        ("æŸ¥è¯¢æŸ¥è¯¢æŸ¥è¯¢", None, "repetition"),
        ("ä½ å¥½ä½ å¥½ä½ å¥½", None, "greeting_repetition"),
        ("asdfghjkl", None, "keyboard_mash"),
        ("test test test", None, "test_input"),
        # Very long inputs
        ("æŸ¥è¯¢" * 50, None, "very_long_repetition"),
        ("è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•è®¢å•", None, "word_repetition"),
        # Mixed language chaos
        ("æŸ¥è¯¢orderçš„status", None, "mixed_language"),
        ("deleteè®¢å•", None, "mixed_delete"),
        ("showæˆ‘çš„orders", None, "mixed_show"),
        # Unusual formats
        ("ã€è®¢å•æŸ¥è¯¢ã€‘", None, "bracket_format"),
        ("=====è®¢å•=====", None, "decorated_text"),
        (">>>æŸ¥è¯¢<<<", None, "arrow_format"),
        ("@è®¢å•#æŸ¥è¯¢$", None, "special_chars"),
        ("è®¢.å•.æŸ¥.è¯¢", None, "dotted_text"),
        # Domain confusion
        ("æ’­æ”¾éŸ³ä¹", None, "wrong_domain"),
        ("æ‰“å¼€ç›¸æœº", None, "wrong_domain"),
        ("å‘é€å¾®ä¿¡", None, "wrong_domain"),
        ("å¯¼èˆªåˆ°åŒ—äº¬", None, "wrong_domain"),
        ("è®¾ç½®é—¹é’Ÿ", None, "wrong_domain"),
        # Technical jargon mixing
        ("SELECT * FROM orders", None, "sql_injection_like"),
        ("{\"action\": \"query\"}", None, "json_format"),
        ("<order>query</order>", None, "xml_format"),
        ("curl -X GET /orders", None, "command_format"),
        ("orders.find({})", None, "code_format"),
    ]

    for text, intent, behavior in low_confidence_cases:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.LOW_CONFIDENCE,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[4]
        ))
        case_id += 1

    # ========== Category 8: Domain-Specific (30 cases) ==========
    domain_specific = [
        ("æŸ¥è¯¢æº¯æºç ", "TRACE_CODE_QUERY", "traceability"),
        ("æ‰«ææ‰¹æ¬¡äºŒç»´ç ", "BATCH_SCAN", "traceability"),
        ("è¿½æº¯äº§å“æ¥æº", "PRODUCT_TRACE", "traceability"),
        ("æŸ¥çœ‹ä¾›åº”é“¾ä¿¡æ¯", "SUPPLY_CHAIN_QUERY", "supply_chain"),
        ("å†·é“¾æ¸©åº¦ç›‘æ§", "COLD_CHAIN_MONITOR", "cold_chain"),
        ("HACCPè®°å½•æŸ¥è¯¢", "HACCP_QUERY", "food_safety"),
        ("GMPåˆè§„æ£€æŸ¥", "GMP_CHECK", "compliance"),
        ("æ‰¹æ¬¡å¬å›", "BATCH_RECALL", "recall"),
        ("åŸæ–™æ‰¹æ¬¡è¿½è¸ª", "MATERIAL_TRACE", "traceability"),
        ("æˆå“æ£€éªŒæŠ¥å‘Š", "PRODUCT_INSPECTION", "quality"),
        # Industry terms
        ("æŸ¥çœ‹BOMæ¸…å•", "BOM_QUERY", "manufacturing"),
        ("MRPè®¡ç®—", "MRP_CALCULATE", "planning"),
        ("WMSåº“ä½æŸ¥è¯¢", "WMS_LOCATION", "warehouse"),
        ("ERPæ•°æ®åŒæ­¥", "ERP_SYNC", "integration"),
        ("IoTè®¾å¤‡çŠ¶æ€", "IOT_STATUS", "iot"),
        # Food industry specific
        ("ä¿è´¨æœŸé¢„è­¦", "SHELF_LIFE_ALERT", "food_safety"),
        ("é…æ–¹æŸ¥è¯¢", "RECIPE_QUERY", "food_production"),
        ("è¥å…»æˆåˆ†åˆ†æ", "NUTRITION_ANALYSIS", "food_info"),
        ("è¿‡æ•åŸæ ‡è¯†", "ALLERGEN_LABEL", "food_safety"),
        ("æœ‰æœºè®¤è¯æŸ¥è¯¢", "ORGANIC_CERT_QUERY", "certification"),
    ]

    for text, intent, behavior in domain_specific:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.DOMAIN_SPECIFIC,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[2]
        ))
        case_id += 1

    # ========== Category 9: Typos and Noise (30 cases) ==========
    typo_cases = [
        ("æŸ¥æ—¬è®¢å•", "ORDER_QUERY", "typo_query"),
        ("åº“å­˜æŸ¥å¾‡", "INVENTORY_QUERY", "typo_inventory"),
        ("ç”Ÿäº§æŠ¥å½ª", "REPORT_PRODUCTION", "typo_report"),
        ("å‘˜å·¥åè›‹", "EMPLOYEE_QUERY", "typo_employee"),
        ("è®¾è¢«çŠ¶æ€", "EQUIPMENT_STATUS", "typo_equipment"),
        ("äº§å“æŸ¥xun", "PRODUCT_TYPE_QUERY", "pinyin_typo"),
        ("è®¢å•chaxun", "ORDER_QUERY", "pinyin_mixed"),
        ("åº“cunæŸ¥è¯¢", "INVENTORY_QUERY", "partial_pinyin"),
        ("shengchanæŠ¥è¡¨", "REPORT_PRODUCTION", "pinyin_chinese"),
        ("yuangongåˆ—è¡¨", "EMPLOYEE_QUERY", "pinyin_list"),
        # Common typos
        ("æŸ¥è¯¢å®šå•", "ORDER_QUERY", "homophone"),
        ("è‹¦å­˜æ•°é‡", "INVENTORY_QUERY", "homophone"),
        ("äº§å“ä»·ä¸ª", "PRODUCT_PRICE", "homophone"),
        ("åœ†å·¥ä¿¡æ¯", "EMPLOYEE_QUERY", "homophone"),
        ("æ¶‰å¤‡ç»´æŠ¤", "EQUIPMENT_MAINTENANCE", "homophone"),
        # With extra characters
        ("æŸ¥è¯¢ï¼Œè®¢å•", "ORDER_QUERY", "extra_punctuation"),
        ("åº“å­˜ã€‚ã€‚ã€‚", "INVENTORY_QUERY", "trailing_dots"),
        ("äº§å“ï¼ï¼", "PRODUCT_TYPE_QUERY", "exclamation"),
        ("å‘˜å·¥???", "EMPLOYEE_QUERY", "question_marks"),
        ("è®¾å¤‡...", "EQUIPMENT_STATUS", "ellipsis"),
        # Spacing issues
        ("æŸ¥ è¯¢ è®¢ å•", "ORDER_QUERY", "extra_spaces"),
        ("åº“å­˜æŸ¥è¯¢", "INVENTORY_QUERY", "no_space_needed"),
        ("äº§å“  ä»·æ ¼", "PRODUCT_PRICE", "double_space"),
        ("å‘˜å·¥\tåˆ—è¡¨", "EMPLOYEE_QUERY", "tab_char"),
        ("è®¾å¤‡\nçŠ¶æ€", "EQUIPMENT_STATUS", "newline"),
    ]

    for text, intent, behavior in typo_cases:
        cases.append(TestCase(
            id=case_id,
            category=TestCategory.TYPO_NOISE,
            input_text=text,
            expected_intent=intent,
            expected_behavior=behavior,
            phase_tested=[2]
        ))
        case_id += 1

    # Fill remaining to reach 500
    while case_id <= 500:
        category = random.choice(list(TestCategory))
        cases.append(TestCase(
            id=case_id,
            category=category,
            input_text=f"æµ‹è¯•ç”¨ä¾‹{case_id}: {random.choice(['æŸ¥è¯¢', 'ä¿®æ”¹', 'åˆ é™¤', 'ç»Ÿè®¡', 'åˆ†æ'])}{random.choice(entities)}",
            expected_intent=None,
            expected_behavior="auto_generated",
            phase_tested=[2]
        ))
        case_id += 1

    return cases

def get_auth_token() -> str:
    """Get authentication token"""
    try:
        response = requests.post(LOGIN_URL, json={
            "username": "factory_admin1",
            "password": "123456"
        }, timeout=10)
        data = response.json()
        if data.get("code") == 200:
            return data["data"]["token"]
    except Exception as e:
        print(f"Login failed: {e}")
    return None

def run_test(test_case: TestCase, session_id: str) -> Dict[str, Any]:
    """Run a single test case"""
    result = {
        "test_id": test_case.id,
        "category": test_case.category.value,
        "input": test_case.input_text,
        "expected_intent": test_case.expected_intent,
        "expected_behavior": test_case.expected_behavior,
        "phases_tested": test_case.phase_tested,
        "success": False,
        "response": None,
        "error": None,
        "latency_ms": 0
    }

    start_time = time.time()

    try:
        # Skip empty inputs
        if not test_case.input_text or not test_case.input_text.strip():
            result["error"] = "Empty input"
            result["latency_ms"] = int((time.time() - start_time) * 1000)
            return result

        response = requests.post(
            RECOGNIZE_URL,
            json={
                "userInput": test_case.input_text,
                "sessionId": session_id
            },
            headers={"Content-Type": "application/json"},
            timeout=30
        )

        result["latency_ms"] = int((time.time() - start_time) * 1000)

        if response.status_code == 200:
            data = response.json()
            result["response"] = data.get("data", {})
            result["success"] = data.get("code") == 200

            # Extract key metrics
            if result["response"]:
                result["matched_intent"] = result["response"].get("intentCode")
                result["confidence"] = result["response"].get("confidence")
                result["match_method"] = result["response"].get("matchMethod")
                result["match_layer"] = result["response"].get("matchLayer")
        else:
            result["error"] = f"HTTP {response.status_code}"

    except requests.exceptions.Timeout:
        result["error"] = "Timeout"
        result["latency_ms"] = 30000
    except Exception as e:
        result["error"] = str(e)
        result["latency_ms"] = int((time.time() - start_time) * 1000)

    return result

def analyze_results(results: List[Dict]) -> Dict[str, Any]:
    """Analyze test results"""
    total = len(results)
    successful = sum(1 for r in results if r["success"])

    # Category breakdown
    category_stats = {}
    for category in TestCategory:
        cat_results = [r for r in results if r["category"] == category.value]
        if cat_results:
            category_stats[category.value] = {
                "total": len(cat_results),
                "successful": sum(1 for r in cat_results if r["success"]),
                "avg_latency": sum(r["latency_ms"] for r in cat_results) / len(cat_results),
                "avg_confidence": sum(r.get("confidence", 0) or 0 for r in cat_results if r.get("confidence")) / max(1, sum(1 for r in cat_results if r.get("confidence")))
            }

    # Match method distribution
    match_methods = {}
    for r in results:
        method = r.get("match_method", "unknown")
        match_methods[method] = match_methods.get(method, 0) + 1

    # Confidence distribution
    confidence_buckets = {"high(>0.8)": 0, "medium(0.5-0.8)": 0, "low(<0.5)": 0, "none": 0}
    for r in results:
        conf = r.get("confidence")
        if conf is None:
            confidence_buckets["none"] += 1
        elif conf > 0.8:
            confidence_buckets["high(>0.8)"] += 1
        elif conf > 0.5:
            confidence_buckets["medium(0.5-0.8)"] += 1
        else:
            confidence_buckets["low(<0.5)"] += 1

    # Phase coverage
    phase_coverage = {1: 0, 2: 0, 3: 0, 4: 0}
    for r in results:
        for phase in r.get("phases_tested", []):
            phase_coverage[phase] += 1

    # Latency stats
    latencies = [r["latency_ms"] for r in results]

    return {
        "summary": {
            "total_tests": total,
            "successful": successful,
            "failed": total - successful,
            "success_rate": f"{successful/total*100:.1f}%"
        },
        "category_stats": category_stats,
        "match_methods": match_methods,
        "confidence_distribution": confidence_buckets,
        "phase_coverage": phase_coverage,
        "latency": {
            "min": min(latencies) if latencies else 0,
            "max": max(latencies) if latencies else 0,
            "avg": sum(latencies) / len(latencies) if latencies else 0,
            "p95": sorted(latencies)[int(len(latencies) * 0.95)] if latencies else 0
        },
        "errors": [r for r in results if r.get("error")][:20]  # First 20 errors
    }

def main():
    print("=" * 60)
    print("AI Intent Recognition System - 500 Test Cases")
    print("=" * 60)
    print(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # Generate test cases
    print("Generating 500 test cases...")
    test_cases = generate_test_cases()
    print(f"Generated {len(test_cases)} test cases")

    # Category distribution
    print("\nCategory Distribution:")
    for category in TestCategory:
        count = sum(1 for tc in test_cases if tc.category == category)
        print(f"  {category.value}: {count}")

    print("\n" + "-" * 60)
    print("Running tests...")
    print("-" * 60)

    results = []
    session_id = f"test-500-{datetime.now().strftime('%Y%m%d%H%M%S')}"

    for i, test_case in enumerate(test_cases):
        result = run_test(test_case, session_id)
        results.append(result)

        # Progress indicator
        if (i + 1) % 50 == 0:
            print(f"Progress: {i + 1}/{len(test_cases)} ({(i+1)/len(test_cases)*100:.0f}%)")

        # Small delay to avoid overwhelming the server
        if (i + 1) % 10 == 0:
            time.sleep(0.5)

    print("\n" + "=" * 60)
    print("Test Results Analysis")
    print("=" * 60)

    analysis = analyze_results(results)

    # Print summary
    print(f"\nğŸ“Š Summary:")
    print(f"   Total Tests: {analysis['summary']['total_tests']}")
    print(f"   Successful: {analysis['summary']['successful']}")
    print(f"   Failed: {analysis['summary']['failed']}")
    print(f"   Success Rate: {analysis['summary']['success_rate']}")

    print(f"\nğŸ“ˆ Category Performance:")
    for cat, stats in analysis['category_stats'].items():
        rate = stats['successful'] / stats['total'] * 100 if stats['total'] > 0 else 0
        print(f"   {cat}: {stats['successful']}/{stats['total']} ({rate:.1f}%) | avg latency: {stats['avg_latency']:.0f}ms | avg conf: {stats['avg_confidence']:.2f}")

    print(f"\nğŸ¯ Match Methods:")
    for method, count in analysis['match_methods'].items():
        print(f"   {method}: {count} ({count/len(results)*100:.1f}%)")

    print(f"\nğŸ“‰ Confidence Distribution:")
    for bucket, count in analysis['confidence_distribution'].items():
        print(f"   {bucket}: {count} ({count/len(results)*100:.1f}%)")

    print(f"\nğŸ”„ Phase Coverage:")
    for phase, count in analysis['phase_coverage'].items():
        print(f"   Phase {phase}: {count} test cases")

    print(f"\nâ±ï¸ Latency:")
    print(f"   Min: {analysis['latency']['min']}ms")
    print(f"   Max: {analysis['latency']['max']}ms")
    print(f"   Avg: {analysis['latency']['avg']:.0f}ms")
    print(f"   P95: {analysis['latency']['p95']}ms")

    # Save results
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_path = f"tests/ai-intent/reports/comprehensive_500_report_{timestamp}.json"

    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": timestamp,
            "analysis": analysis,
            "results": results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ Detailed report saved to: {report_path}")
    print(f"\nEnd Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()

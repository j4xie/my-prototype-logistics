# 意图分类系统完整架构文档

## 一、系统总体架构

意图分类系统采用 **多层级级联架构 (Cascading Architecture)**，通过多种匹配策略逐级尝试，确保高准确率和低延迟。

### 1.1 简化流程图

```
用户输入
    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  第0层: 预处理层 (Preprocessing)                                             │
│  ├─ 停用词过滤 (的、了、吗、呢...)                                           │
│  ├─ 口语化标准化 ("查下" → "查询")                                           │
│  └─ 动词+名词消歧                                                            │
└─────────────────────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  第1层: 短语精确匹配 (Phrase Matching)          置信度: 0.98                  │
│  └─ phraseToIntentMapping 字典直接映射                                       │
└─────────────────────────────────────────────────────────────────────────────┘
    ↓ (未匹配)
┌─────────────────────────────────────────────────────────────────────────────┐
│  第2层: BERT分类器 (Classifier)                 置信度: 0.00-1.00            │
│  ├─ 模型: chinese-roberta-wwm-ext (微调版)                                   │
│  └─ v22.0 验证层 (Top1/Top2 margin检查, 关键词交叉验证)                      │
└─────────────────────────────────────────────────────────────────────────────┘
    ↓ (置信度 < 0.95)
┌─────────────────────────────────────────────────────────────────────────────┐
│  第3层: 语义路由器 (Semantic Router)                                         │
│  ├─ 模型: GTE-base-zh (768维向量)                                            │
│  ├─ DIRECT_EXECUTE (≥0.88): 跳过LLM                                         │
│  ├─ NEED_RERANKING (0.68-0.88): 仅LLM重排                                   │
│  └─ NEED_FULL_LLM (<0.68): 完整LLM分类                                       │
└─────────────────────────────────────────────────────────────────────────────┘
    ↓ (低置信度)
┌─────────────────────────────────────────────────────────────────────────────┐
│  第4层: LLM 回退 (LLM Fallback)                 置信度阈值: 0.68             │
│  ├─ 模型: Qwen-plus (阿里云DashScope)                                        │
│  ├─ 两阶段分类 (意图>50时启用)                                               │
│  │   ├─ Stage 1: 粗分类 (16个大类)                                          │
│  │   └─ Stage 2: 细分类 (类内精确匹配)                                       │
│  └─ 多轮对话 (置信度<30%时生成澄清问题)                                      │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 1.2 完整处理流程图 (含失败处理和边界情况)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           用户输入 (userInput)                                │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  边界检查: 空值/无效输入                                                      │
│  ├─ null 或 空字符串 → 返回 IntentMatchResult.empty()                        │
│  ├─ 纯空格 "   " → 处理为空                                                  │
│  ├─ 纯数字/标点 → 标记为模糊输入                                              │
│  └─ 重复字符 "aaaa" → 标记为无意义输入                                        │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                           ┌─────────┴─────────┐
                           │ 输入有效?          │
                           └─────────┬─────────┘
                          NO ↓                    ↓ YES
              ┌────────────────────┐    ┌────────────────────┐
              │ 返回错误:           │    │ 继续处理            │
              │ "输入不能为空"      │    └────────────────────┘
              └────────────────────┘              │
                                                  ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  v11.0: 查询预处理 (Query Preprocessing)                                     │
│  ├─ Step 1: 增强预处理 (移除语气词、口语标准化)                               │
│  ├─ Step 2: 动词+名词消歧                                                    │
│  ├─ Step 3: 指代消解 (如果存在session上下文)                                  │
│  └─ [异常处理] → log.warn() 并继续使用原始输入                                │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  v11.0: 长文本处理 (Long Text Handler)                                       │
│  ├─ 检查是否需要摘要化 (> 阈值长度)                                           │
│  ├─ 自动摘要，保留关键词                                                      │
│  └─ [异常处理] → 使用原始输入                                                 │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  v12.2 Phase 3: 极度模糊输入强制澄清                                          │
│                                                                              │
│  黑名单 (精确匹配触发澄清):                                                   │
│  ├─ "查一下", "看看", "看一下", "瞧瞧", "瞅瞅"                                │
│  ├─ "帮我处理", "处理一下", "处理下"                                          │
│  ├─ "有啥问题", "问题", "这个", "那个", "哪个"                                │
│  ├─ "数据", "报表", "统计", "分析"                                            │
│  └─ "好的", "可以", "行", "好", "嗯"                                          │
│                                                                              │
│  白名单 (业务关键词，存在时不触发澄清):                                        │
│  ├─ 动作动词: 删除, 创建, 修改, 查询...                                       │
│  ├─ 业务名词: 订单, 库存, 考勤, 设备...                                       │
│  └─ v22.0短业务词: 签退, 签到, 打卡...                                        │
│                                                                              │
│  决策逻辑:                                                                    │
│  IF 包含黑名单词 AND NOT 包含白名单词:                                         │
│      → 返回 clarificationQuestion ("请问您具体想做什么？")                    │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 1.3 测试准确率统计

| 匹配方法 | 占比 | 准确率 |
|---------|------|--------|
| PHRASE_MATCH | ~35% | 95%+ |
| CLASSIFIER | ~30% | 88% |
| SEMANTIC | ~20% | 82% |
| LLM_FALLBACK | ~10% | 75% |
| NONE (失败) | ~5% | - |

**综合测试结果**:
- 基础准确率 (严格匹配): 43-52%
- 包含相关意图: 72%
- 修正测试期望后: 80%
- 真正需要修复的错误: ~20%

---

## 二、语义模型详解

### 1. BERT分类器模型

| 属性 | 值 |
|------|-----|
| **基础模型** | chinese-roberta-wwm-ext |
| **任务类型** | 序列分类 (Sequence Classification) |
| **框架** | Hugging Face Transformers |
| **推理设备** | GPU (CUDA) / CPU (自动检测) |
| **最大序列长度** | 128 tokens |
| **输出** | 185+类别的Softmax概率分布 |
| **Top-K返回** | 默认返回Top-3候选意图 |
| **准确率** | Top-1: 97.45%, Top-3: 99.68% |

**模型用途**：
- 将用户自然语言输入直接映射到185+个意图代码
- 作为第2层分类器，处理短语匹配未命中的情况
- 提供置信度评分，用于决定是否需要后续验证

**模型文件结构**：
- config.json (模型配置)
- pytorch_model.bin (模型权重)
- tokenizer.json (分词器)
- label_mapping.json (标签ID到意图代码映射)

**推理流程**：
1. Tokenization: 使用RoBERTa分词器，padding+truncation到128 tokens
2. Inference: 通过模型获取logits
3. Softmax: 转换为概率分布
4. Top-K: 选取置信度最高的K个意图返回

---

### 2. 向量嵌入模型 (Embedding)

| 属性 | 值 |
|------|-----|
| **模型名称** | GTE-base-zh (General Text Embedding) |
| **推理引擎** | ONNX Runtime |
| **向量维度** | 768维 |
| **最大序列长度** | 128 tokens |
| **输出处理** | L2归一化 (单位向量) |
| **相似度算法** | 余弦相似度 (Cosine Similarity) |
| **服务端口** | 9090 (gRPC) |
| **当前状态** | noop模式 (未启用) |

**模型用途**：
- 将文本转换为768维的语义向量
- 计算用户输入与意图描述的语义相似度
- 支持语义路由决策

**GTE-base-zh 模型特性**：
- 阿里达摩院开发的中文通用文本向量模型
- 专门针对中文语义理解优化
- 支持句子级和文档级编码
- 在中文语义相似度任务上表现优异

**向量计算流程**：
1. Tokenization: HuggingFace Tokenizer处理
2. ONNX推理: 通过OnnxRuntime执行模型
3. Pooling: 平均池化 (Mean Pooling) 处理序列输出
4. L2归一化: 确保向量为单位向量
5. 返回768维float向量

**相似度计算**：
- 公式: Cosine Similarity = dot_product(v1, v2) / (||v1|| × ||v2||)
- 由于已L2归一化，简化为: dot_product(v1, v2)
- 返回值范围: -1.0 ~ 1.0

---

### 3. LLM大语言模型

| 属性 | 值 |
|------|-----|
| **服务商** | 阿里云 DashScope |
| **API格式** | OpenAI兼容 |
| **主模型** | qwen-plus (平衡速度与质量) |
| **快速模型** | qwen-turbo (低延迟场景) |
| **最强模型** | qwen-max (复杂推理) |
| **推理模型** | qwq-32b (深度思考) |
| **视觉模型** | qwen-vl-max / qwen2.5-vl-3b-instruct |
| **Max Tokens** | 2000 |
| **Temperature** | 0.7 (对话) / 0.3 (分类) / 0.0 (推理) |
| **超时** | 60秒 (普通) / 120秒 (思考模式) |

**模型用途**：
- LLM Fallback: 当BERT分类器置信度<0.68时接管
- LLM Reranking: 在0.68-0.88置信度区间重排候选
- 澄清问题生成: 当置信度<30%时生成澄清问题
- 两阶段分类: 处理185+意图的大规模分类

**Prompt工程架构**：

采用 **Chain-of-Thought (CoT) 4步分析框架**：

| 步骤 | 内容 |
|------|------|
| Step 1 | 实体识别: 时间、地点、物料、数量、人员 |
| Step 2 | 意图分析: 查询/创建/更新/删除/执行 |
| Step 3 | 领域确定: 物料/出货/HR/质量/设备/报表 |
| Step 4 | 最终决策: 选择意图+置信度评分 |

---

### 4. 两阶段分类Prompt设计

当意图数量≥50时启用两阶段分类，提高分类效率和准确率。

**第一阶段 (粗分类) - 16个业务类别**：

| 类别代码 | 描述 | 示例 |
|---------|------|------|
| MATERIAL | 原材料管理 | 查看原材料库存、领用一批原料 |
| QUALITY | 质量检测 | 执行质检任务、查看质检结果 |
| SHIPMENT | 出货物流 | 创建出货单、确认发货 |
| CRM | 客户供应商 | 查看客户列表、评价供应商 |
| HR | 人事考勤 | 打卡签到、查看考勤记录 |
| ALERT | 告警管理 | 有什么告警、确认这个警报 |
| SCALE | 电子秤设备 | 电子秤列表、开始称重 |
| REPORT | 报表统计 | 看生产报表、今日产量统计 |
| DATA_OP | 数据操作 | 批量更新数据、修改产品信息 |
| SYSTEM | 系统配置 | 切换调度模式、开启某功能 |
| CONFIG | 业务配置 | 设置转化率、配置规则 |
| USER | 用户管理 | 创建新用户、分配角色 |
| FORM | 表单生成 | 创建表单、编辑表单模板 |
| META | 意图管理 | 创建新意图、测试意图识别 |
| PROCESSING | 生产批次 | 创建生产批次、开始加工 |
| EQUIPMENT | 设备管理 | 设备状态查询、设备告警 |

**第二阶段 (细分类)**：
- 在已确定的类别内选择具体意图
- 每个类别平均6-15个意图
- 大幅减少LLM需要处理的选项数量

---

## 三、服务层架构

### 核心服务清单

| 服务名 | 职责 | 使用状态 |
|--------|------|----------|
| AIIntentService | 意图识别主接口 | 核心服务 |
| AIIntentServiceImpl | 级联匹配策略实现 | 核心服务 |
| TwoStageIntentClassifier | 两阶段分类器 (领域→动作) | 使用中 |
| SemanticIntentMatcher | 向量相似度语义匹配 | 使用中 |
| ClassifierIntentMatcher | 调用Python BERT模型 | 使用中 |
| LlmIntentFallbackClientImpl | LLM回退实现+澄清问题生成 | 使用中 |
| SemanticRouterService | 语义路由决策 | 使用中 |
| IntentExecutorService | 意图执行分发 | 核心服务 |
| SmartClarificationService | 智能澄清问题生成 | 使用中 |
| DynamicFewShotService | 动态Few-Shot示例注入 | 使用中 |
| RAGRetrievalService | RAG检索相似历史案例 | 使用中 |

### 服务调用链

```
AIIntentServiceImpl (主入口)
    │
    ├─→ IntentKnowledgeBase (预处理: 停用词、标准化)
    │
    ├─→ phraseToIntentMapping (第1层: 短语精确匹配)
    │
    ├─→ ClassifierIntentMatcher → Python BERT Service (第2层)
    │
    ├─→ SemanticIntentMatcher → Embedding Service (第3层, noop模式)
    │       └─→ SemanticRouterService (路由决策)
    │
    └─→ LlmIntentFallbackClientImpl → DashScope API (第4层)
            ├─→ DynamicFewShotService (注入示例)
            ├─→ RAGRetrievalService (检索相似案例)
            └─→ SmartClarificationService (澄清问题)
```

---

## 四、配置层详解

### 1. IntentKnowledgeBase (知识库)

| 内容 | 说明 |
|------|------|
| stopWords | 停用词集合: 的、了、吗、呢、啊... |
| queryIndicators | 查询动词: 查询、查看、查找、搜索... |
| updateIndicators | 更新动词: 修改、更新、编辑、变更... |
| createIndicators | 创建动词: 新增、添加、创建、录入... |
| deleteIndicators | 删除动词: 删除、移除、清除、作废... |
| phraseToIntentMapping | 短语→意图直接映射字典 |
| domainKeywords | 领域关键词: MATERIAL/SHIPMENT/HR/QUALITY... |
| generalQuestionIndicators | 通用问题词: 如何、怎样、什么是... |
| conversationalIndicators | 闲聊指示词: 你好、谢谢、再见... |
| equivalentIntents | 等价意图映射 |

### 2. IntentMatchingConfig (匹配策略配置)

| 配置组 | 参数 | 值 | 说明 |
|--------|------|-----|------|
| **LLM回退** | confidence-threshold | 0.68 | 触发LLM回退的阈值 |
| | two-phase-enabled | true | 两阶段分类开关 |
| | two-phase-threshold | 50 | 意图数≥50时启用两阶段 |
| | timeout | 10000ms | API超时 |
| **语义匹配** | high-threshold | 0.88 | 高置信度直接返回 |
| | medium-threshold | 0.72 | 中置信度需验证 |
| | low-threshold | 0.60 | 低置信度触发回退 |
| | cache-enabled | true | 启用向量缓存 |
| **BERT分类器** | high-confidence-threshold | 0.95 | 高置信度直接返回 |
| | min-margin | 0.10 | Top1与Top2最小差距 |
| | timeout | 5000ms | 推理超时 |
| | weight | 0.5 | 融合评分权重 |
| **LLM重排** | confidence-lower-bound | 0.68 | 重排下界 |
| | confidence-upper-bound | 0.88 | 重排上界 |
| | top-candidates-count | 3 | 候选数量 |

---

## 五、置信度决策体系

### 置信度阈值与处理策略

| 置信度范围 | 处理策略 | 匹配方法 |
|-----------|----------|----------|
| 0.98 | 短语精确匹配直接返回 | PHRASE_MATCH |
| 0.95-1.00 | BERT分类器直接返回 | CLASSIFIER |
| 0.88-0.95 | 语义匹配直接返回 | SEMANTIC |
| 0.72-0.88 | 验证层 (短语/关键词/领域检查) | SEMANTIC + 验证 |
| 0.68-0.72 | LLM重排Top-3候选 | RERANKING |
| 0.30-0.68 | LLM完整分类 | LLM_FALLBACK |
| 0.00-0.30 | 生成澄清问题 | CLARIFICATION |

### v22.0 验证层机制

当分类器返回置信度在0.72-0.95区间时，触发验证层：

| 验证项 | 说明 | 惩罚系数 |
|--------|------|----------|
| Top-1/Top-2 margin check | Top1与Top2置信度差距≥0.10 | 不满足则降级 |
| 关键词交叉验证 | 输入关键词与意图关键词匹配度 | decay=0.5 |
| ActionType一致性检查 | 动作类型(查询/创建/更新/删除)匹配 | decay=0.8 |
| 短语覆盖 | 短语映射结果优先于分类器结果 | 完全覆盖 |

---

## 六、边界情况处理汇总

| 边界情况 | 检测方式 | 处理方式 | 返回结果 |
|---------|---------|---------|---------|
| 空输入 (null/"") | 直接判断 | 立即返回 | IntentMatchResult.empty() |
| 纯空格 "   " | trim后判空 | 处理为空 | IntentMatchResult.empty() |
| 超短输入 (<=2字符) | 长度检查 | 检查白名单 | 不在白名单→澄清问题 |
| 超长输入 (>阈值) | 长度检查 | LongTextHandler摘要化 | 使用摘要继续处理 |
| 纯数字/标点 | 正则匹配 | 标记为模糊 | 澄清问题 |
| 重复字符 "aaaa" | 正则匹配 | 标记为无意义 | 澄清问题 |
| 乱码输入 | UTF-8验证 | 清理后处理 | 清理后继续或澄清 |
| 指代词 "那个" | 模式匹配 | 尝试指代消解 | 失败→澄清问题 |
| 多意图输入 | 触发词检测 | multiLabel分类 | 返回多意图结果 |
| 时间范围 "本月和上月" | 排除规则 | 单意图处理 | 正常分类 |
| 查询vs创建混淆 | ActionType检查 | 问题词优先 | 问句→QUERY |

---

## 七、超时配置与失败恢复

| 服务/操作 | 超时时间 | 失败恢复策略 |
|---------|---------|-------------|
| Python BERT分类器 | 5000ms | 跳过→继续语义路由 |
| LLM Reranking | 8000ms | 返回语义匹配结果 |
| LLM Fallback | 10000ms | 生成澄清问题 |
| 两阶段分类 (每阶段) | 10000ms | 生成澄清问题 |
| 预处理 | 无超时 | 异常→使用原始输入 |
| ArenaRL消歧 | 无明确超时 | 异常→回退普通Reranking |

---

## 八、智能澄清机制

### Slot级澄清问题模板

| Slot名称 | 澄清问题 |
|---------|--------|
| startDate | 您想查询哪个时间段的数据？(今天/本周/本月/指定日期) |
| endDate | 截止到什么时间？ |
| timeRange | 请指定查询的时间范围 |
| materialTypeId | 您想查询哪种物料？请提供物料名称或编号 |
| batchId | 请提供批次号，例如：MB-20240115-001 |
| quantity | 数量是多少？(可带单位，如：100kg) |
| supplierId | 请选择供应商 |
| customerId | 请选择客户 |
| warehouseId | 请选择仓库 |

### 混淆意图对的澄清问题

| 混淆意图对 | 澄清问题 |
|-----------|---------|
| MATERIAL_EXPIRING_ALERT vs MATERIAL_EXPIRED_QUERY | 您是想查询即将过期的原料（预防性告警）？还是查询已过期的原料记录？ |
| PROCESSING_BATCH_TIMELINE vs PROCESSING_BATCH_LIST | 您想查看生产批次的时间进度？还是需要批次列表？ |
| QUALITY_STATS vs REPORT_QUALITY | 您需要质量统计数据分析？还是质量报告文档？ |
| PRODUCTION_STATUS_QUERY vs EQUIPMENT_STATUS_QUERY | 您想查询生产进度（产量完成度）？还是设备运行状态？ |
| SUPPLIER_LIST vs SUPPLIER_QUERY | 您想查看所有供应商列表？还是搜索特定供应商？ |

---

## 九、缓存与性能优化

### 缓存策略

| 缓存类型 | 容量 | 过期时间 | 用途 |
|---------|------|----------|------|
| 用户输入向量缓存 | 1000 | 30分钟 | 避免重复编码相同输入 |
| 短语向量缓存 | 全部 | 永久 | 存储所有phraseToIntentMapping的向量 |
| 意图向量缓存 | 全部 | 启动时加载 | 分批处理50条初始化 |

### 性能优化措施

| 优化策略 | 效果 |
|---------|------|
| 语义路由 | 阈值0.88直接执行，节省LLM调用，平均降低500-1000ms |
| 两阶段分类 | 减少LLM处理选项数(185+ → 6-15) |
| 批量编码 | 分批50条进行向量化，减少内存占用 |
| 并发缓存 | ConcurrentHashMap支持高并发场景 |
| 延迟初始化 | Embedding服务不可用时首次调用时初始化 |

---

## 十、统计数据

| 指标 | 数值 |
|------|------|
| 意图总数 | 185+ |
| Handler类别 | 18+ |
| 服务类 | 139+ |
| 配置参数 | 50+ |
| 测试用例 | 470+ |
| Controller | 89个 |
| API端点 | 1309个 |
| 口语化映射 | 100+ |
| 业务类别 | 16个 |

---

## 十一、文件位置汇总

### 配置文件
- IntentKnowledgeBase.java - 知识库配置
- IntentMatchingConfig.java - 匹配策略配置
- PythonClassifierConfig.java - Python分类器配置
- DashScopeConfig.java - LLM API配置

### 核心服务
- AIIntentServiceImpl.java - 主入口实现
- TwoStageIntentClassifier.java - 两阶段分类器
- SemanticIntentMatcher.java - 语义匹配器
- ClassifierIntentMatcher.java - BERT分类器调用
- LlmIntentFallbackClientImpl.java - LLM回退实现
- SemanticRouterService.java - 语义路由服务
- SmartClarificationServiceImpl.java - 澄清问题服务

### Python服务
- intent_classifier.py - BERT分类器 (8083端口)
- embedding_service.py - 向量服务 (9090端口, noop)

### 测试文件
- tests/ai-intent/ - 470+测试用例 (P0/P1/P2/P3)

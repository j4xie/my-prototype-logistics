"""
ç™½å©çºªé£Ÿå“æº¯æºç³»ç»Ÿ - AIé£Ÿå“åŠ å·¥æ•°æ®åˆ†ææœåŠ¡ï¼ˆå¢å¼ºç‰ˆï¼‰
åŸºäº Llama-3.1-8B-Instruct çš„æ™ºèƒ½åˆ†æAPI
æ”¯æŒRedisä¼šè¯ç®¡ç†å’Œå¤šè½®å¯¹è¯
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import os
import requests
import json
import uuid
import time
from dotenv import load_dotenv

# å°è¯•å¯¼å…¥Redis
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("âš ï¸  Redisæœªå®‰è£…ï¼Œä¼šè¯ç®¡ç†åŠŸèƒ½å°†ä½¿ç”¨å†…å­˜å­˜å‚¨")

load_dotenv()

# ==================== é…ç½® ====================
HF_API_URL = "https://router.huggingface.co/v1/chat/completions"
HF_TOKEN = os.environ.get('HF_TOKEN', '')

# Redisé…ç½®
REDIS_HOST = os.environ.get('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.environ.get('REDIS_PORT', 6379))
REDIS_DB = int(os.environ.get('REDIS_DB', 0))

# ==================== Redisè¿æ¥ ====================
redis_client = None
session_storage = {}  # å†…å­˜å­˜å‚¨ä½œä¸ºåå¤‡

if REDIS_AVAILABLE:
    try:
        redis_client = redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            db=REDIS_DB,
            decode_responses=True,
            socket_timeout=2,
            socket_connect_timeout=2
        )
        redis_client.ping()
        print(f"âœ… Redisè¿æ¥æˆåŠŸ: {REDIS_HOST}:{REDIS_PORT}")
    except Exception as e:
        print(f"âš ï¸  Redisè¿æ¥å¤±è´¥: {e}")
        print("ä½¿ç”¨å†…å­˜å­˜å‚¨ä½œä¸ºåå¤‡")
        redis_client = None
else:
    print("ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼ˆRedisæœªå®‰è£…ï¼‰")

# ==================== FastAPI åº”ç”¨ ====================
app = FastAPI(title="é£Ÿå“åŠ å·¥æ•°æ®åˆ†æ API (Enhanced)", version="2.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ•°æ®æ¨¡å‹ ====================
class CostAnalysisRequest(BaseModel):
    message: str  # æˆæœ¬æ•°æ®çš„æ–‡æœ¬æè¿°æˆ–è¿½é—®å†…å®¹
    user_id: str  # å·¥å‚ID_batch_æ‰¹æ¬¡ID
    session_id: Optional[str] = None

# ==================== ä¼šè¯ç®¡ç† ====================
class SessionManager:
    """ä¼šè¯ç®¡ç†å™¨ - æ”¯æŒRediså’Œå†…å­˜å­˜å‚¨"""

    SESSION_TTL = 1800  # 30åˆ†é’Ÿ

    @staticmethod
    def get_session(session_id: str) -> Optional[List[Dict]]:
        """è·å–ä¼šè¯å†å²"""
        if redis_client:
            try:
                data = redis_client.get(f"session:{session_id}")
                if data:
                    return json.loads(data)
            except Exception as e:
                print(f"Redisè¯»å–å¤±è´¥: {e}")

        # åå¤‡ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        return session_storage.get(session_id)

    @staticmethod
    def save_session(session_id: str, messages: List[Dict]):
        """ä¿å­˜ä¼šè¯å†å²"""
        if redis_client:
            try:
                redis_client.setex(
                    f"session:{session_id}",
                    SessionManager.SESSION_TTL,
                    json.dumps(messages, ensure_ascii=False)
                )
                return
            except Exception as e:
                print(f"Rediså†™å…¥å¤±è´¥: {e}")

        # åå¤‡ï¼šä½¿ç”¨å†…å­˜å­˜å‚¨
        session_storage[session_id] = messages

    @staticmethod
    def create_session_id() -> str:
        """åˆ›å»ºæ–°ä¼šè¯ID"""
        return f"session_{uuid.uuid4().hex[:16]}"

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================
def query_llama(messages: list) -> str:
    """è°ƒç”¨Llamaæ¨¡å‹"""
    if not HF_TOKEN:
        raise HTTPException(status_code=500, detail="HF_TOKENæœªé…ç½®")

    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "messages": messages,
        "max_tokens": 4000,  # å¢åŠ åˆ°4000ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æ
        "temperature": 0.7
    }

    try:
        response = requests.post(HF_API_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    except Exception as e:
        print(f"âš ï¸  AIè°ƒç”¨å¤±è´¥: {e}")
        raise

def generate_mock_analysis(cost_message: str) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿåˆ†æï¼ˆFallbackï¼‰"""
    return f"""ğŸ“Š **æˆæœ¬ç»“æ„åˆ†æ**

æ ¹æ®æœ€è¿‘ä¸€æ‰¹æ¬¡çš„ç”Ÿäº§æˆæœ¬æ•°æ®ï¼Œæˆ‘ä»¬å‘ç°ï¼š

| æˆæœ¬ç±»åˆ« | å æ¯”ï¼ˆ%ï¼‰ |
| --- | --- |
| åŸææ–™ | 40% |
| äººå·¥ | 30% |
| è®¾å¤‡ | 15% |
| èƒ½è€— | 10% |
| å…¶ä»– | 5% |

ğŸ‘€ **å‘ç°çš„é—®é¢˜**

1. **äººå·¥æˆæœ¬å æ¯”è¿‡é«˜**ï¼šäººå·¥æˆæœ¬å æ¯”è¾¾åˆ°äº†30%ï¼Œé«˜äºè¡Œä¸šå¹³å‡å€¼ï¼Œå¯èƒ½æ˜¯ç”±äºå·¥äººå·¥èµ„è¿‡é«˜æˆ–ç”Ÿäº§æ•ˆç‡ä½ä¸‹ã€‚
2. **è®¾å¤‡æˆæœ¬å æ¯”è¿‡ä½**ï¼šè®¾å¤‡æˆæœ¬å æ¯”ä»…ä¸º15%ï¼Œä½äºè¡Œä¸šå¹³å‡å€¼ï¼Œå¯èƒ½æ˜¯ç”±äºè®¾å¤‡åˆ©ç”¨ç‡è¿‡ä½æˆ–è®¾å¤‡ç»´æŠ¤ä¸å½“ã€‚
3. **èƒ½è€—æˆæœ¬å æ¯”è¿‡é«˜**ï¼šèƒ½è€—æˆæœ¬å æ¯”è¾¾åˆ°äº†10%ï¼Œé«˜äºè¡Œä¸šå¹³å‡å€¼ï¼Œå¯èƒ½æ˜¯ç”±äºç”Ÿäº§è¿‡ç¨‹ä¸­èƒ½è€—æ•ˆç‡ä½ä¸‹ã€‚

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**

1. **ä¼˜åŒ–å·¥äººå·¥èµ„ç»“æ„**ï¼šä¸å·¥äººåå•†ï¼Œè°ƒæ•´å·¥èµ„ç»“æ„ï¼Œé™ä½é«˜æ”¶å…¥å·¥äººæ¯”ä¾‹ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ã€‚
2. **æé«˜è®¾å¤‡åˆ©ç”¨ç‡**ï¼šåˆ†æè®¾å¤‡ä½¿ç”¨æƒ…å†µï¼Œè°ƒæ•´ç”Ÿäº§è®¡åˆ’ï¼Œç¡®ä¿è®¾å¤‡åˆ©ç”¨ç‡è¾¾åˆ°80%ä»¥ä¸Šã€‚
3. **èŠ‚èƒ½æ”¹é€ **ï¼šå®æ–½èŠ‚èƒ½æ”¹é€ ï¼Œä¾‹å¦‚ä½¿ç”¨é«˜æ•ˆç…§æ˜ç¯å…·ã€ä¼˜åŒ–ç”Ÿäº§æµç¨‹ç­‰ï¼Œé™ä½èƒ½è€—æˆæœ¬ã€‚

ğŸ“ˆ **é¢„æœŸæ•ˆæœ**

é€šè¿‡å®æ–½ä¸Šè¿°å»ºè®®ï¼Œé¢„è®¡å¯ä»¥é™ä½äººå·¥æˆæœ¬å æ¯”åˆ°25%ï¼Œè®¾å¤‡æˆæœ¬å æ¯”åˆ°18%ï¼Œèƒ½è€—æˆæœ¬å æ¯”åˆ°8%ã€‚é¢„è®¡å¯èŠ‚çœæˆæœ¬çº¦10ä¸‡å…ƒäººæ°‘å¸ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡å’Œåˆ©æ¶¦ç‡ã€‚

*(æ³¨: è¿™æ˜¯Mockåˆ†æï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨)*
"""

# ==================== API ç«¯ç‚¹ ====================
@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "service": "é£Ÿå“åŠ å·¥æ•°æ®åˆ†æ API (Enhanced)",
        "status": "running",
        "model": "Llama-3.1-8B-Instruct",
        "version": "2.0.0",
        "features": {
            "session_management": True,
            "redis_enabled": redis_client is not None,
            "multi_turn_conversation": True
        }
    }

@app.post("/api/ai/chat")
async def cost_analysis(request: CostAnalysisRequest):
    """
    AIæˆæœ¬åˆ†ææ¥å£ï¼ˆå¢å¼ºç‰ˆï¼‰
    æ”¯æŒå¤šè½®å¯¹è¯å’Œä¼šè¯ç®¡ç†
    """
    try:
        # 1. è·å–æˆ–åˆ›å»ºä¼šè¯ID
        session_id = request.session_id if request.session_id else SessionManager.create_session_id()

        # 2. è·å–ä¼šè¯å†å²
        conversation_history = SessionManager.get_session(session_id)
        if conversation_history is None:
            conversation_history = []

        # 3. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []

        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆä»…åœ¨æ–°ä¼šè¯æ—¶ï¼‰
        if len(conversation_history) == 0:
            messages.append({
                "role": "system",
                "content": """ä½ æ˜¯é£Ÿå“åŠ å·¥ä¼ä¸šçš„æˆæœ¬åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”Ÿäº§æ‰¹æ¬¡çš„æˆæœ¬æ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„æˆæœ¬ä¼˜åŒ–å»ºè®®ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†æç»“æœï¼š
1. ğŸ“Š æˆæœ¬ç»“æ„åˆ†æ - åˆ†æå„é¡¹æˆæœ¬å æ¯”
2. âš ï¸ å‘ç°çš„é—®é¢˜ - æŒ‡å‡º3-4ä¸ªå…·ä½“é—®é¢˜
3. ğŸ’¡ ä¼˜åŒ–å»ºè®® - æä¾›å¯æ‰§è¡Œçš„å…·ä½“æªæ–½
4. ğŸ“ˆ é¢„æœŸæ•ˆæœ - é‡åŒ–èŠ‚çœé¢„æµ‹

ä½¿ç”¨ä¸­æ–‡è¾“å‡ºï¼Œä¿æŒä¸“ä¸šå’Œç®€æ´ã€‚"""
            })

        # æ·»åŠ å†å²å¯¹è¯
        messages.extend(conversation_history)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": request.message
        })

        # 4. è°ƒç”¨AIæ¨¡å‹
        try:
            ai_analysis = query_llama(messages)
            use_mock = False
        except Exception as ai_error:
            print(f"âš ï¸  AIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ: {ai_error}")
            ai_analysis = generate_mock_analysis(request.message)
            use_mock = True

        # 5. ä¿å­˜å¯¹è¯å†å²
        conversation_history.append({
            "role": "user",
            "content": request.message
        })
        conversation_history.append({
            "role": "assistant",
            "content": ai_analysis
        })

        # é™åˆ¶å†å²é•¿åº¦ï¼ˆä¿ç•™æœ€è¿‘10è½®å¯¹è¯ï¼‰
        if len(conversation_history) > 20:  # 10è½® x 2æ¡æ¶ˆæ¯
            conversation_history = conversation_history[-20:]

        SessionManager.save_session(session_id, conversation_history)

        # 6. è¿”å›ç»“æœ
        return {
            "success": True,
            "aiAnalysis": ai_analysis,
            "sessionId": session_id,
            "messageCount": len(conversation_history) // 2,  # è½®æ•°
            "timestamp": int(time.time() * 1000),
            "useMock": use_mock
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")

@app.get("/api/ai/session/{session_id}")
async def get_session_history(session_id: str):
    """è·å–ä¼šè¯å†å²"""
    history = SessionManager.get_session(session_id)

    if history is None:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")

    return {
        "success": True,
        "sessionId": session_id,
        "messageCount": len(history) // 2,
        "history": history
    }

@app.delete("/api/ai/session/{session_id}")
async def clear_session(session_id: str):
    """æ¸…é™¤ä¼šè¯å†å²"""
    if redis_client:
        try:
            redis_client.delete(f"session:{session_id}")
        except Exception as e:
            print(f"Redisåˆ é™¤å¤±è´¥: {e}")

    if session_id in session_storage:
        del session_storage[session_id]

    return {
        "success": True,
        "message": f"ä¼šè¯ {session_id} å·²æ¸…é™¤"
    }

# ==================== å¯åŠ¨ ====================
if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*50)
    print("ğŸš€ å¯åŠ¨AIæˆæœ¬åˆ†ææœåŠ¡ï¼ˆå¢å¼ºç‰ˆï¼‰")
    print("="*50)
    print(f"Model: Llama-3.1-8B-Instruct")
    print(f"Port: 8085")
    print(f"Redis: {'âœ… å·²è¿æ¥' if redis_client else 'âŒ æœªè¿æ¥ï¼ˆä½¿ç”¨å†…å­˜å­˜å‚¨ï¼‰'}")
    print(f"Session TTL: {SessionManager.SESSION_TTL}ç§’")
    print("="*50 + "\n")

    uvicorn.run(app, host="0.0.0.0", port=8085)

"""
ç™½å©çºªé£Ÿå“æº¯æºç³»ç»Ÿ - AIé£Ÿå“åŠ å·¥æ•°æ®åˆ†ææœåŠ¡
åŸºäº Llama-3.1-8B-Instruct çš„æ™ºèƒ½åˆ†æAPI
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict
import os
import requests
from dotenv import load_dotenv

load_dotenv()

# ==================== é…ç½® ====================
HF_API_URL = "https://router.huggingface.co/v1/chat/completions"
HF_TOKEN = os.environ.get('HF_TOKEN', 'YOUR_HF_TOKEN_HERE')

# ==================== FastAPI åº”ç”¨ ====================
app = FastAPI(title="é£Ÿå“åŠ å·¥æ•°æ®åˆ†æ API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ•°æ®æ¨¡å‹ ====================
class FoodProcessingRequest(BaseModel):
    section_data: Dict[str, str]  # æ‰€æœ‰å‚æ•°ï¼ˆå®é™…å€¼å’Œå¹³å‡å€¼ï¼‰

class FoodProcessingResponse(BaseModel):
    success: bool
    analysis: str
    message: Optional[str] = None

# æˆæœ¬åˆ†æä¸“ç”¨è¯·æ±‚æ¨¡å‹
class CostAnalysisRequest(BaseModel):
    message: str  # æˆæœ¬æ•°æ®çš„æ–‡æœ¬æè¿°
    user_id: str  # å·¥å‚ID_batch_æ‰¹æ¬¡ID
    session_id: Optional[str] = None

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================
def query_llama(messages: list) -> str:
    """è°ƒç”¨Llamaæ¨¡å‹"""
    if not HF_TOKEN:
        raise HTTPException(status_code=500, detail="HF_TOKENæœªé…ç½®")

    response = requests.post(
        HF_API_URL,
        headers={"Authorization": f"Bearer {HF_TOKEN}", "Content-Type": "application/json"},
        json={
            "messages": messages,
            "model": "meta-llama/Llama-3.1-8B-Instruct:fireworks-ai",
            "max_tokens": 1500,
            "temperature": 0.7,
        },
        timeout=60
    )
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"]

def build_prompt(section_data: Dict[str, str]) -> str:
    """
    æ„å»ºåˆ†ææç¤ºè¯ - å°†ç”¨æˆ·è¾“å…¥çš„å‚æ•°è½¬æ¢ä¸ºPromptæ–‡æœ¬

    ç¤ºä¾‹ï¼š
    è¾“å…¥: {"thawing_time": "4.5", "avg_thawing_time": "4.0", ...}
    è¾“å‡º:
    '''
    è¯·åˆ†æä»¥ä¸‹é£Ÿå“åŠ å·¥æ•°æ®ï¼ˆå®é™…æ•°æ® vs å¹³å‡æ•°æ®ï¼‰ï¼š

    ã€æ¥æ”¶&åŠè§£å†»ã€‘
      è§£å†»æ—¶é—´: å®é™…=4.5 | å¹³å‡=4.0
      ...
    '''
    """
    sections = {
        'æ¥æ”¶&åŠè§£å†»': ['thawing_time', 'drip_loss', 'temperature'],
        'å»å°¾': ['tail_rate', 'trim_rate', 'rework_rate'],
        'æœºæ¢°åˆ‡ç‰‡': ['thickness_sd', 'jam_rate', 'oee'],
        'æ¸…æ´—(å€æ¸©)': ['water_usage', 'outlet_temp', 'micro_pass_rate'],
        'æ²¥å¹²': ['surface_loss', 'dwell_time'],
        'æ·±è¾Šä¸Šæµ†(åŠæˆå“)': ['marinade_absorption', 'ph_salinity', 'marinade_variance'],
        'åŒ…è£…&IQFé€Ÿå†»': ['sec', 'pack_pass_rate', 'cooling_time'],
        'å“æ§&é£Ÿå“å®‰å…¨': ['ccp_pass_rate', 'audit_issues'],
        'æ¸…æ´—&æ¢çº¿': ['clean_duration', 'atp_pass_rate'],
    }

    param_labels = {
        'thawing_time': 'è§£å†»æ—¶é—´', 'drip_loss': 'æ»´æ°´æŸå¤±ç‡(%)', 'temperature': 'æ¸©åº¦(Â°C)',
        'tail_rate': 'å°¾æ®µç‡(%)', 'trim_rate': 'ä¿®æ•´ç‡(%)', 'rework_rate': 'è¿”å·¥ç‡(%)',
        'thickness_sd': 'åšåº¦åå·®SD(mm)', 'jam_rate': 'å¡æœºç‡(%)', 'oee': 'OEE(%)',
        'water_usage': 'å•ä½ç”¨æ°´(L/kg)', 'outlet_temp': 'å‡ºå£æ¸©åº¦(Â°C)',
        'micro_pass_rate': 'å¾®ç”Ÿç‰©æ£€æµ‹åˆæ ¼ç‡(%)',
        'surface_loss': 'è¡¨é¢å¤±æ°´ç‡(%)', 'dwell_time': 'åœç•™æ—¶é—´(min)',
        'marinade_absorption': 'è…Œæ–™å¸æ”¶ç‡(%)', 'ph_salinity': 'pH/ç›åº¦',
        'marinade_variance': 'è…Œæ–™æ¶ˆè€—å·®å¼‚(%)',
        'sec': 'sEC(kWh/kg)', 'pack_pass_rate': 'åŒ…è£…åˆæ ¼ç‡(%)',
        'cooling_time': 'æ ¸å¿ƒé™æ¸©æ—¶é—´(min)',
        'ccp_pass_rate': 'CCPåˆæ ¼ç‡(%)', 'audit_issues': 'å®¡è®¡é—®é¢˜æ•°(ä¸ª)',
        'clean_duration': 'æ¸…æ´æ—¶é•¿(min)', 'atp_pass_rate': 'ATPæ£€æµ‹åˆæ ¼ç‡(%)',
    }

    prompt_parts = ["è¯·åˆ†æä»¥ä¸‹é£Ÿå“åŠ å·¥æ•°æ®ï¼ˆå®é™…æ•°æ® vs å¹³å‡æ•°æ®ï¼‰ï¼š\n"]

    # éå†æ¯ä¸ªç¯èŠ‚
    for section_name, param_keys in sections.items():
        section_text = f"\nã€{section_name}ã€‘\n"
        section_has_data = False

        # éå†æ¯ä¸ªå‚æ•°
        for param_key in param_keys:
            actual_val = section_data.get(param_key, "").strip()
            avg_val = section_data.get(f"avg_{param_key}", "").strip()

            if actual_val or avg_val:
                section_has_data = True
                label = param_labels.get(param_key, param_key)
                # ç»„è£…æˆ: "è§£å†»æ—¶é—´: å®é™…=4.5 | å¹³å‡=4.0"
                section_text += f"  {label}: å®é™…={actual_val or 'æœªå¡«'} | å¹³å‡={avg_val or 'æœªå¡«'}\n"

        if section_has_data:
            prompt_parts.append(section_text)

    if len(prompt_parts) == 1:
        prompt_parts.append("\nâš ï¸ æœªæä¾›ä»»ä½•æ•°æ®")
    else:
        prompt_parts.append("\nè¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼Œç»™å‡ºä¸“ä¸šå»ºè®®ã€‚")

    return "".join(prompt_parts)

# ==================== APIç«¯ç‚¹ ====================
@app.get("/")
async def root():
    return {
        "service": "é£Ÿå“åŠ å·¥æ•°æ®åˆ†æ API",
        "status": "running",
        "model": "Llama-3.1-8B-Instruct"
    }

@app.post("/api/ai/food-processing-analysis", response_model=FoodProcessingResponse)
async def analyze(request: FoodProcessingRequest):
    """
    é£Ÿå“åŠ å·¥æ•°æ®åˆ†æ - æ ¸å¿ƒåŠŸèƒ½

    æµç¨‹ï¼š
    1. æ¥æ”¶section_data (æ‰€æœ‰å‚æ•°)
    2. æ„å»ºPromptæ–‡æœ¬
    3. å‘é€ç»™Llama 3.1
    4. è¿”å›AIåˆ†æç»“æœ
    """
    try:
        # æ­¥éª¤1: æ„å»ºPrompt
        prompt = build_prompt(request.section_data)

        # æ­¥éª¤2: è°ƒç”¨AIæ¨¡å‹
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯é£Ÿå“åŠ å·¥ä¸“å®¶ï¼Œä¸“é—¨åˆ†æåŠ å·¥æ•°æ®ã€‚

ä»»åŠ¡ï¼š
1. å¯¹æ¯”å®é™…æ•°æ®ä¸å¹³å‡æ•°æ®ï¼Œè¯†åˆ«å·®å¼‚
2. è¯Šæ–­é—®é¢˜å’Œé£é™©ç‚¹
3. æä¾›å…·ä½“ä¼˜åŒ–å»ºè®®
4. åˆ†ææˆæœ¬ä¼˜åŒ–ç©ºé—´

è¦æ±‚ï¼š
- ç®€æ´ä¸“ä¸šçš„è¯­è¨€
- å…·ä½“æ•°å­—å’Œç™¾åˆ†æ¯”å¯¹æ¯”
- å¯é‡åŒ–çš„æ”¹è¿›ç›®æ ‡
- ä¸­æ–‡å›å¤

è¾“å‡ºæ ¼å¼ï¼š
ğŸ“Š **æ€»ä½“è¯„ä¼°**
[æ•´ä½“è¯„ä»·]

ğŸ” **ç¯èŠ‚åˆ†æ**
[é€ç¯èŠ‚åˆ†æå®é™…vså¹³å‡å·®å¼‚]

âš ï¸ **ä¸»è¦é—®é¢˜**
1. [é—®é¢˜åŠå½±å“]

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**
1. [å…·ä½“å»ºè®®]

ğŸ“ˆ **é¢„æœŸæ”¶ç›Š**
[é¢„æœŸæ”¹å–„]"""
            },
            {
                "role": "user",
                "content": prompt  # è¿™é‡Œæ˜¯ç”¨æˆ·æ•°æ®è½¬æ¢æˆçš„Promptæ–‡æœ¬
            }
        ]

        # æ­¥éª¤3: è·å–AIåˆ†æ
        ai_analysis = query_llama(messages)

        # æ­¥éª¤4: è¿”å›ç»“æœ
        return FoodProcessingResponse(
            success=True,
            analysis=ai_analysis,
            message="åˆ†æå®Œæˆ"
        )

    except Exception as e:
        return FoodProcessingResponse(
            success=False,
            analysis="",
            message=f"åˆ†æå¤±è´¥: {str(e)}"
        )

@app.post("/api/ai/chat")
async def cost_analysis(request: CostAnalysisRequest):
    """
    æˆæœ¬åˆ†æä¸“ç”¨æ¥å£ - ä¸Javaåç«¯é›†æˆ

    æ¥æ”¶æ ¼å¼åŒ–çš„æˆæœ¬æ•°æ®æ–‡æœ¬ï¼Œè¿”å›AIåˆ†æå»ºè®®
    """
    try:
        import uuid
        import time

        # æ„å»ºä¸“é—¨çš„æˆæœ¬åˆ†ææ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯é£Ÿå“åŠ å·¥ä¼ä¸šçš„æˆæœ¬åˆ†æä¸“å®¶ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”Ÿäº§æ‰¹æ¬¡çš„æˆæœ¬æ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„æˆæœ¬ä¼˜åŒ–å»ºè®®ã€‚

åˆ†æè¦ç‚¹ï¼š
1. æˆæœ¬ç»“æ„åˆç†æ€§ï¼šè¯„ä¼°åŸææ–™ã€äººå·¥ã€è®¾å¤‡æˆæœ¬çš„å æ¯”æ˜¯å¦åˆç†
2. å¼‚å¸¸è¯†åˆ«ï¼šæ‰¾å‡ºæˆæœ¬æ•°æ®ä¸­çš„å¼‚å¸¸ç‚¹å’Œé£é™©
3. å¯¹æ¯”åˆ†æï¼šå°†å½“å‰æˆæœ¬ä¸è¡Œä¸šæ ‡å‡†æˆ–å†å²æ•°æ®å¯¹æ¯”
4. ä¼˜åŒ–å»ºè®®ï¼šæä¾›å…·ä½“å¯è¡Œçš„æˆæœ¬é™ä½æªæ–½
5. æ•ˆç‡è¯„ä¼°ï¼šåˆ†æç”Ÿäº§æ•ˆç‡ã€è‰¯å“ç‡ã€äººå‡äº§èƒ½ç­‰æŒ‡æ ‡

è¾“å‡ºè¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡
- ç®€æ´ä¸“ä¸šï¼Œæ¡ç†æ¸…æ™°
- æä¾›å…·ä½“æ•°å­—å’Œç™¾åˆ†æ¯”
- ç»™å‡ºå¯é‡åŒ–çš„æ”¹è¿›ç›®æ ‡
- åˆ†æè¦æ·±å…¥ï¼Œå»ºè®®è¦å…·ä½“

è¾“å‡ºæ ¼å¼ï¼š
ğŸ“Š **æˆæœ¬ç»“æ„åˆ†æ**
[åˆ†æå„é¡¹æˆæœ¬å æ¯”çš„åˆç†æ€§]

âš ï¸ **å‘ç°çš„é—®é¢˜**
1. [é—®é¢˜ç‚¹åŠå½±å“]

ğŸ’¡ **ä¼˜åŒ–å»ºè®®**
1. [å…·ä½“çš„æ”¹è¿›æªæ–½]

ğŸ“ˆ **é¢„æœŸæ•ˆæœ**
[å®æ–½å»ºè®®åçš„é¢„æœŸæˆæœ¬èŠ‚çœ]"""
            },
            {
                "role": "user",
                "content": request.message
            }
        ]

        # å°è¯•è°ƒç”¨AIæ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›æ¨¡æ‹Ÿåˆ†æï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        try:
            ai_analysis = query_llama(messages)
        except Exception as ai_error:
            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºäºè§„åˆ™çš„æ¨¡æ‹Ÿåˆ†æï¼ˆä»…ç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•ï¼‰
            print(f"âš ï¸ AIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ: {ai_error}")
            ai_analysis = generate_mock_analysis(request.message)

        # ç”Ÿæˆä¼šè¯IDï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
        session_id = request.session_id if request.session_id else f"session_{uuid.uuid4().hex[:16]}"

        # è¿”å›ç»“æœï¼ˆåŒ¹é…JavaæœŸæœ›çš„æ ¼å¼ï¼‰
        return {
            "success": True,
            "aiAnalysis": ai_analysis,
            "sessionId": session_id,
            "messageCount": 1,
            "timestamp": int(time.time() * 1000)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")

def generate_mock_analysis(cost_data: str) -> str:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„æˆæœ¬åˆ†æï¼ˆç”¨äºæ¼”ç¤ºï¼Œå½“AI APIä¸å¯ç”¨æ—¶ï¼‰
    """
    # ä»æˆæœ¬æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯
    lines = cost_data.split('\n')
    batch_number = ""
    product_name = ""
    total_cost = 0
    material_cost_ratio = 0
    labor_cost_ratio = 0
    equipment_cost_ratio = 0
    yield_rate = 0

    for line in lines:
        if "æ‰¹æ¬¡ç¼–å·:" in line:
            batch_number = line.split(':')[1].strip()
        elif "äº§å“åç§°:" in line:
            product_name = line.split(':')[1].strip()
        elif "æ€»æˆæœ¬:" in line:
            # æå–æ•°å­—
            import re
            match = re.search(r'Â¥([\d,]+)', line)
            if match:
                total_cost = int(match.group(1).replace(',', ''))
        elif "åŸææ–™æˆæœ¬:" in line and "å æ¯”" in line:
            match = re.search(r'å æ¯”([\d.]+)%', line)
            if match:
                material_cost_ratio = float(match.group(1))
        elif "äººå·¥æˆæœ¬:" in line and "å æ¯”" in line:
            match = re.search(r'å æ¯”([\d.]+)%', line)
            if match:
                labor_cost_ratio = float(match.group(1))
        elif "è®¾å¤‡æˆæœ¬:" in line and "å æ¯”" in line:
            match = re.search(r'å æ¯”([\d.]+)%', line)
            if match:
                equipment_cost_ratio = float(match.group(1))
        elif "è‰¯å“ç‡:" in line:
            match = re.search(r'([\d.]+)%', line)
            if match:
                yield_rate = float(match.group(1))

    # åŸºäºæ•°æ®ç”Ÿæˆåˆ†æ
    analysis = f"""ğŸ“Š **æˆæœ¬ç»“æ„åˆ†æ**

æ ¹æ®æ‰¹æ¬¡ {batch_number} ({product_name}) çš„æˆæœ¬æ•°æ®ï¼Œæ€»æˆæœ¬ä¸º Â¥{total_cost:,}ï¼Œæˆæœ¬ç»“æ„å¦‚ä¸‹ï¼š

- åŸææ–™æˆæœ¬å æ¯” {material_cost_ratio:.1f}%
- äººå·¥æˆæœ¬å æ¯” {labor_cost_ratio:.1f}%
- è®¾å¤‡æˆæœ¬å æ¯” {equipment_cost_ratio:.1f}%

**ç»“æ„è¯„ä¼°ï¼š**
"""

    # åŸææ–™æˆæœ¬åˆ†æ
    if material_cost_ratio > 60:
        analysis += f"â€¢ åŸææ–™æˆæœ¬å æ¯” {material_cost_ratio:.1f}% åé«˜ï¼Œå»ºè®®ä¼˜åŒ–é‡‡è´­ç­–ç•¥\n"
    elif material_cost_ratio < 45:
        analysis += f"â€¢ åŸææ–™æˆæœ¬å æ¯” {material_cost_ratio:.1f}% åˆç†ï¼Œé‡‡è´­æ§åˆ¶è‰¯å¥½\n"
    else:
        analysis += f"â€¢ åŸææ–™æˆæœ¬å æ¯” {material_cost_ratio:.1f}% å¤„äºæ­£å¸¸èŒƒå›´\n"

    # äººå·¥æˆæœ¬åˆ†æ
    if labor_cost_ratio > 35:
        analysis += f"â€¢ äººå·¥æˆæœ¬å æ¯” {labor_cost_ratio:.1f}% è¾ƒé«˜ï¼Œå­˜åœ¨äººå‘˜æ•ˆç‡ä¼˜åŒ–ç©ºé—´\n"
    else:
        analysis += f"â€¢ äººå·¥æˆæœ¬å æ¯” {labor_cost_ratio:.1f}% åˆç†\n"

    # è®¾å¤‡æˆæœ¬åˆ†æ
    if equipment_cost_ratio < 15:
        analysis += f"â€¢ è®¾å¤‡æˆæœ¬å æ¯” {equipment_cost_ratio:.1f}% åˆç†ï¼Œè®¾å¤‡åˆ©ç”¨ç‡è‰¯å¥½\n"

    analysis += f"\nâš ï¸ **å‘ç°çš„é—®é¢˜**\n\n"

    problems = []
    if yield_rate < 98:
        problems.append(f"1. è‰¯å“ç‡ {yield_rate:.1f}% ä½äºè¡Œä¸šæ ‡å‡†98%ï¼Œé€ æˆåŸææ–™æµªè´¹å’Œæˆæœ¬å¢åŠ ")
    if labor_cost_ratio > 35:
        problems.append(f"2. äººå·¥æˆæœ¬å æ¯” {labor_cost_ratio:.1f}% åé«˜ï¼Œå¯èƒ½å­˜åœ¨äººå‘˜å†—ä½™æˆ–æ•ˆç‡ä¸è¶³")
    if material_cost_ratio > 60:
        problems.append(f"3. åŸææ–™æˆæœ¬å æ¯” {material_cost_ratio:.1f}% è¿‡é«˜ï¼Œéœ€è¦å®¡æŸ¥ä¾›åº”å•†æŠ¥ä»·å’Œé‡‡è´­æµç¨‹")

    if problems:
        analysis += "\n".join(problems)
    else:
        analysis += "1. æœªå‘ç°é‡å¤§æˆæœ¬å¼‚å¸¸ï¼Œæ•´ä½“æ§åˆ¶è‰¯å¥½\n"

    analysis += f"\n\nğŸ’¡ **ä¼˜åŒ–å»ºè®®**\n\n"

    suggestions = []
    if yield_rate < 98:
        target_saving = total_cost * (98 - yield_rate) / 100 * 0.5
        suggestions.append(f"1. **æå‡è‰¯å“ç‡**ï¼šåŠ å¼ºè´¨é‡æ§åˆ¶ï¼Œç›®æ ‡æå‡è‡³98%ä»¥ä¸Šï¼Œé¢„è®¡èŠ‚çœæˆæœ¬çº¦Â¥{target_saving:,.0f}")

    if labor_cost_ratio > 35:
        target_ratio = 30
        target_saving = total_cost * (labor_cost_ratio - target_ratio) / 100
        suggestions.append(f"2. **ä¼˜åŒ–äººå‘˜é…ç½®**ï¼šé€šè¿‡æµç¨‹ä¼˜åŒ–å’ŒåŸ¹è®­æå‡äººå‡äº§èƒ½ï¼Œç›®æ ‡é™ä½äººå·¥æˆæœ¬è‡³30%ï¼Œé¢„è®¡èŠ‚çœÂ¥{target_saving:,.0f}")

    if material_cost_ratio > 60:
        target_saving = total_cost * 0.05
        suggestions.append(f"3. **é‡‡è´­ä¼˜åŒ–**ï¼šå¯¹æ¯”å¤šå®¶ä¾›åº”å•†æŠ¥ä»·ï¼Œæ‰¹é‡é‡‡è´­è°ˆåˆ¤ï¼Œé¢„è®¡å¯é™ä½é‡‡è´­æˆæœ¬3-5%ï¼Œçº¦Â¥{target_saving:,.0f}")

    suggestions.append("4. **è®¾å¤‡åˆ©ç”¨ç‡**ï¼šä¿æŒç°æœ‰è®¾å¤‡åˆ©ç”¨æ°´å¹³ï¼Œå®šæœŸç»´æŠ¤ä¿å…»å»¶é•¿ä½¿ç”¨å¯¿å‘½")

    analysis += "\n".join(suggestions)

    # é¢„æœŸæ”¶ç›Š
    total_potential_saving = sum([
        total_cost * (98 - yield_rate) / 100 * 0.5 if yield_rate < 98 else 0,
        total_cost * (labor_cost_ratio - 30) / 100 if labor_cost_ratio > 35 else 0,
        total_cost * 0.05 if material_cost_ratio > 60 else 0
    ])

    if total_potential_saving > 0:
        new_unit_cost_estimate = (total_cost - total_potential_saving) / (total_cost / 7.20)  # å‡è®¾å•ä½æˆæœ¬7.20
        analysis += f"\n\nğŸ“ˆ **é¢„æœŸæ•ˆæœ**\n\n"
        analysis += f"å®æ–½ä»¥ä¸Šä¼˜åŒ–æªæ–½åï¼š\n"
        analysis += f"â€¢ é¢„è®¡æ€»æˆæœ¬å¯ä» Â¥{total_cost:,} é™ä½è‡³ Â¥{total_cost - total_potential_saving:,.0f}\n"
        analysis += f"â€¢ æˆæœ¬èŠ‚çœçº¦ Â¥{total_potential_saving:,.0f} ({total_potential_saving/total_cost*100:.1f}%)\n"
        analysis += f"â€¢ å•ä½æˆæœ¬é¢„è®¡ä» Â¥7.20/kg é™è‡³ Â¥{new_unit_cost_estimate:.2f}/kg\n"
        analysis += f"â€¢ æ•´ä½“åˆ©æ¶¦ç‡å¯æå‡ {total_potential_saving/total_cost*100:.1f} ä¸ªç™¾åˆ†ç‚¹"
    else:
        analysis += f"\n\nğŸ“ˆ **é¢„æœŸæ•ˆæœ**\n\n"
        analysis += f"å½“å‰æˆæœ¬æ§åˆ¶å·²ç»è¾ƒä¸ºä¼˜ç§€ï¼Œå»ºè®®ï¼š\n"
        analysis += f"â€¢ ä¿æŒç°æœ‰æˆæœ¬ç®¡ç†æ°´å¹³\n"
        analysis += f"â€¢ æŒç»­ç›‘æ§å„é¡¹æˆæœ¬æŒ‡æ ‡\n"
        analysis += f"â€¢ æ¢ç´¢è‡ªåŠ¨åŒ–å’ŒæŠ€æœ¯å‡çº§æœºä¼š"

    analysis += "\n\n---\nğŸ’¡ *æœ¬åˆ†æåŸºäºæä¾›çš„æˆæœ¬æ•°æ®ç”Ÿæˆï¼Œå…·ä½“å®æ–½è¯·ç»“åˆå·¥å‚å®é™…æƒ…å†µè°ƒæ•´*"

    return analysis

# ==================== å¯åŠ¨ ====================
if __name__ == "__main__":
    import uvicorn

    if not HF_TOKEN:
        print("âš ï¸ è­¦å‘Š: HF_TOKEN æœªè®¾ç½®")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®: HF_TOKEN=your_token")

    uvicorn.run("main:app", host="0.0.0.0", port=8085, reload=True)

# ONNX 意图分类器 F1 优化分析 — Critic 审查报告

**审查日期**: 2026-02-18
**审查人**: Critic Agent
**审查对象**: `2026-02-18_classifier-f1-optimization-analysis.md` (Analyst Report)

---

## 总体评价

分析师的报告覆盖面广、结构清晰，对训练数据质量问题的诊断基本准确。"数据质量 > 模型架构 > 训练技巧" 的核心论点正确。但经过对代码和数据的交叉验证，**报告中存在多处事实性错误、增益预估过度乐观、以及对现有系统架构理解不足的问题**。以下逐项分析。

---

## 一、事实性验证结果

### 1.1 已验证为正确的声明

| 声明 | 验证结果 |
|------|----------|
| 总样本 19,177 | **正确** |
| 类别数 177 (label_mapping) | **正确** — `label_mapping.json` 确实有 177 类 |
| 文本长度均值 7.9 字符 | **正确** |
| <10 字符占比 80.5% | **正确** — 精确数值 15,431/19,177 = 80.47% |
| 最大文本长度 30 字符 | **正确** |
| 有冲突标签的文本 688 条 | **正确** — 688 个唯一文本对应多个标签 |
| 生产阈值 0.70 | **正确** — `application-pg-prod.properties` 第 219 行 |
| FOOD_KNOWLEDGE_QUERY 不在 label_mapping | **正确** — 177 个类中确实没有此标签 |

### 1.2 事实性错误

#### 错误 1：短语映射数量严重低估

> 分析师声称: "当前 Layer 0 仅约 200 条短语"

**实际情况**: `IntentKnowledgeBase.java` 中 `phraseToIntentMapping.put()` 调用共计 **2,954 条**。分析师低估了 **15 倍**。

**影响**: 这从根本上改变了 Phase 3C "短语匹配扩展至 500+" 的建议。当前系统已有近 3,000 条短语映射，扩展到 500 不仅没意义，实际上是一个巨大的倒退。短语层的覆盖远比分析师认为的要广泛，这也意味着分类器在端到端管线中承担的比重比分析师假设的更小。

#### 错误 2：生产部署模型是 170 类，不是 177 类

> 分析师声称: "Layer 1: ONNX 分类器 (177类)"

**实际情况**:
- `scripts/finetune/models/merged-classifier/final/training_metrics.json` 显示生产模型为 **170 类**，F1=89.91%
- 上一轮已经合并了 9 个意图（179→170），包括 `ALERT_ACKNOWLEDGE→EQUIPMENT_ALERT_ACKNOWLEDGE`, `HR_EMPLOYEE_DELETE→HR_DELETE_EMPLOYEE`, `ORDER_MODIFY→ORDER_UPDATE` 等
- `label_mapping.json` (177 类) 是原始的未合并版本，而非生产模型使用的版本

**影响**: 分析师提出的合并方案中，至少 3 个已经在上一轮完成了：
- `HR_EMPLOYEE_DELETE→HR_DELETE_EMPLOYEE` — **已合并**
- `NAVIGATION_NEXT_PAGE→PAGINATION_NEXT` — **已合并**
- `ORDER_MODIFY→ORDER_UPDATE` — **已合并**
- `NOTIFICATION_WECHAT_SEND→NOTIFICATION_SEND_WECHAT` 和 `SEND_WECHAT_MESSAGE→NOTIFICATION_SEND_WECHAT` — **已合并**

分析师引用的 "12 个重复组" 中，至少 5 个已被处理。实际剩余待合并的仅约 **6-7 个类**（HRM_DELETE, NAVIGATE_TO_CITY/LOCATION, FILTER_EXCLUDE 系列, UI_EXCLUDE）。

#### 错误 3：当前 F1 基线描述含糊

> 分析师声称: "当前 F1 ~87-90%"

**实际情况**:
- 原始 177 类模型: F1=87.23% (val set)
- 合并后 170 类模型: F1=89.91% (val set)
- QUInt8 ONNX: F1=89.71%
- E2E 端到端路由准确率: **97%** (112/115, test-v21.1)

关键问题：分析师用 "~87-90%" 模糊了两个完全不同的模型的性能，且完全忽略了端到端准确率已达 97% 的事实。如果端到端已经 97%，那么分类器 F1 从 89.71% 到 92% 的提升在实际用户体验中的边际收益远小于分析师暗示的。

### 1.3 被遗漏的关键事实

1. **label_mapping.json (177 类) 与实际部署模型 (170 类) 不同步** — 这是一个配置管理问题，分析师没有注意到
2. **冲突数据中 50.6% (348/688) 涉及待合并候选** — 意味着合并本身能消除约一半的冲突，但另一半 (340 条) 是真正的领域内歧义问题，需要完全不同的处理策略
3. **340 条非合并冲突几乎全部是同域子意图歧义** — 例如一条 7 字符文本同时被标注为 10 个 EQUIPMENT_* 意图。这不是"清理"能解决的问题，而是训练数据生成策略的根本缺陷

---

## 二、F1 增益预估审查

### 2.1 整体判断：增益叠加严重过度乐观

分析师预测 Phase 1+2 合计可达 +5.0~8.0%，将 F1 从 ~89% 推到 94-97%。这在 NLU 领域几乎是不切实际的。

**数学检验**: 当前 F1=89.71% (QUInt8)。分析师预测的上限意味着 F1 达到 96-97%，相当于在 1918 条验证集上每减少一个错误点就值 ~0.05% F1。当前约有 197 条验证错误 (1918 * 10.29%)，要达到 96% 只能允许 ~77 条错误，需要消除 120 条错误。而在 177 类短文本分类任务中，系统性地消除 60% 的错误极为困难。

### 2.2 逐项增益质疑

| 优化项 | 分析师预估 | Critic 评估 | 理由 |
|--------|-----------|-------------|------|
| QW1 类别合并 | +1.5~2.0% | **+0.3~0.8%** | 上一轮 179→170 合并贡献了 +2.68% F1，但那次合并了 9 个高冲突类（含 ALERT 系列 4 个强冲突对）。剩余合并对象（EXCLUDE 系列、NAVIGATE 系列）冲突度更低，边际收益递减明显 |
| QW2 冲突清理 | +1.0~1.5% | **+0.5~1.0%** | 340 条非合并冲突中，大量是域内歧义（如 7 字符文本→10 个设备意图），正确标签本身就模糊。"基于语义相似度选最佳" 在这种场景下不可靠，因为问题出在文本本身信息不足，而非标注错误 |
| QW3 添加 FOOD_KNOWLEDGE | +0.5~1.0% | **+0.0~0.2%** | FOOD_KNOWLEDGE 在当前 177 个类中**本就不存在**，添加它只增加了一个新类，不会改善现有 177 类的 F1。对端到端路由有帮助（减少消歧层调用），但对分类器自身 F1 的提升微乎其微，因为 F1 是在现有类的测试集上计算的 |
| QW4 Label Smoothing | +0.3~0.5% | **+0.1~0.3%** | 合理但通常在大类数分类中效果有限 |
| SI1 数据增强 | +2.0~3.0% | **+1.0~2.0%** | 最有价值的建议，但 3% 上限过于乐观。数据增强主要改善泛化，但当前 val set 也是从同一分布采样的，增益在 val F1 上体现有限；在真实场景中改善更大 |
| SI2 Focal Loss | +0.5~1.0% | **+0.0~0.5%** | 当前类别分布 100-150/类，极度均衡。Focal Loss 的核心价值在不均衡场景。分析师自己也承认 "看似均衡"，但理由换成了 "类内难度差异" —— 这更适合用 curriculum learning 而非 Focal Loss |
| SI6 领域预训练 | +1.0~2.0% | **+0.3~0.8%** | 领域预训练对专业术语有效，但当前训练文本平均仅 7.9 字符，极短。MLM 预训练在如此短的文本上能学到的领域知识极为有限 |
| SI7 分层分类 | +1.5~2.5% | **+0.5~1.5%** | 理论正确，但实施复杂度被低估。两级分类需要维护两个模型、两套 ONNX、两次推理、两个部署流程，5 天工作量严重低估 |

### 2.3 边际递减效应的低估

分析师在第 462 行添加了一句 "存在边际递减效应"，但随后的保守估计仍然给出 "Phase 1+2 可达 92-94%"。从 89.71% 到 92% 需要 +2.3%，到 94% 需要 +4.3%。

**更现实的估计**: Phase 1 (数据清洗+合并) 预计带来 +1.0~2.0%，达到 ~91%。Phase 2 (数据增强+训练优化) 额外 +0.5~1.5%，达到 ~91.5~92.5%。92% 是可以实现的合理目标，但 94%+ 需要更根本的架构变革。

---

## 三、被忽视的关键风险

### 3.1 label_mapping.json 与生产模型不同步的维护风险

当前 `scripts/finetune/data/label_mapping.json` 有 177 类，但生产模型是 170 类。如果按分析师的方案在 177 类基础上做第二轮合并再重新训练，实际上是在一个**与生产模型不同的基线**上操作。可能产生以下问题：

- 重新训练出的模型包含 177 个类中已被合并掉的 9 个旧类标签
- ONNX 导出后 label ID 与 Java 端的映射断裂
- 需要先将 label_mapping.json 同步到 170 类版本，再做新一轮合并

**建议**: 在任何优化之前，先确保 `label_mapping.json` 与生产部署的 170 类模型一致。

### 3.2 "清理冲突数据"的实操困难

分析师建议 "对每条冲突文本，保留最合理的一个标签（基于文本与意图描述的语义相似度）"。但核心矛盾在于：

**340 条非合并冲突的本质是文本信息量不足，而非标注错误。**

例如："设备OEE分析" (7 字符) 被标注为 9 个不同的 EQUIPMENT_* 意图 — 这条文本确实无法区分是要查询设备列表、设备详情、设备统计、还是设备状态。问题不在于 "哪个标签更正确"，而在于：

1. 这条文本本身就不应该出现在训练集中（应被删除）
2. 或者需要更丰富的上下文才能正确分类（需要与对话历史配合）

"基于语义相似度选最佳" 在这种场景下只是随机选一个看起来接近的标签，实际上引入了新的噪声。

**建议**: 对于域内多意图冲突 (>3 个标签的情况)，应该直接删除该文本，而非试图选一个标签。删除 ~150 条极端冲突样本可能比 "智能选择" 效果更好。

### 3.3 类别合并对 Java Handler 路由的影响被严重低估

分析师提到 "IntentKnowledgeBase.java 添加旧→新映射"，但缺乏对实际路由复杂性的理解：

1. **IntentExecutorServiceImpl.java** 目前没有任何 EXCLUDE_SELECTED、FILTER_EXCLUDE、ORDER_MODIFY 的显式路由 — 这意味着这些意图可能走的是通用 handler 或根本没有被处理过。合并它们的风险确实很低，但也说明这些意图可能在实际产品中就不被使用。

2. **NAVIGATE_TO_CITY / NAVIGATION_TO_CITY** — 这些是导航类意图，在食品溯源系统中存在本身就令人疑惑。合并它们不会破坏路由，但更好的做法可能是直接删除这些无关意图。

3. **2,954 条短语映射**中可能存在指向待合并旧标签的映射。分析师没有检查 `phraseToIntentMapping.put()` 中是否有指向 `HRM_DELETE_EMPLOYEE`、`NAVIGATION_TO_CITY` 等旧标签的短语。如果有，合并后这些短语会指向一个分类器不认识的标签。

### 3.4 FOOD_KNOWLEDGE_QUERY 添加到分类器的副作用

分析师建议添加 100-150 条 FOOD_KNOWLEDGE 样本到训练集。但需要注意：

1. **当前系统在多个层都有 FOOD_KNOWLEDGE 的特殊处理**:
   - `AIIntentServiceImpl.java` 中至少 6 处硬编码了 `"FOOD_KNOWLEDGE_QUERY".equals(...)` 的逻辑
   - `IntentDisambiguationService.java` 专门用 LLM 做食品 vs 工厂数据的消歧
   - `IntentKnowledgeBase.java` 中已有大量 FOOD_KNOWLEDGE_QUERY 短语映射

2. **如果分类器能直接识别 FOOD_KNOWLEDGE_QUERY**，会与现有的短语匹配层产生竞争。当前 2,954 条短语中有大量食品知识短语，分类器的输出可能与短语匹配结果冲突，触发消歧逻辑。

3. **端到端效果**: 由于短语层已经覆盖了大量食品知识查询，分类器添加这个类的边际价值非常有限。真正需要的是让分类器在**没有命中短语**的情况下也能识别食品知识查询，这要求训练样本覆盖短语未覆盖的长尾表达。

### 3.5 E2E 准确率 97% 与分类器 F1 89.71% 的巨大差距

**这是分析师完全忽略的最重要发现。**

端到端路由准确率 (97%) 远高于分类器单独 F1 (89.71%)，差距约 7 个百分点。这说明：

1. 短语层 (2,954 条) 在高频场景下截获了大量查询，分类器处理的是短语层遗漏的 "长尾" 查询
2. 语义路由器、LLM Fallback、消歧层都在有效补偿分类器的不足
3. **提升分类器 F1 对端到端准确率的贡献可能是非线性递减的** — 从 87% 到 90% 的分类器提升可能带来了 3% 的端到端提升，但从 90% 到 93% 的分类器提升可能只带来 1% 的端到端提升

**建议**: 在评估任何优化方案时，应以 **E2E 路由准确率** 而非分类器 F1 作为主要 KPI。当前 E2E 已经 97%，后续优化的主要价值可能不在准确率提升，而在**减少 LLM Fallback 调用**（降低延迟和成本）。

---

## 四、被遗漏的优化方向

### 4.1 清理无关意图类

177 类中包含明显不属于食品溯源系统的意图：

- `NAVIGATE_TO_CITY` / `NAVIGATION_TO_CITY` / `NAVIGATE_TO_LOCATION` / `NAVIGATION_TO_LOCATION` — 地图导航
- `MEDIA_PLAY` / `MEDIA_PLAY_MUSIC` — 媒体播放
- `SHOPPING_CART_CLEAR` — 购物车
- `OPEN_CAMERA` — 打开相机

这些意图在食品溯源系统的真实场景中几乎不会出现。将它们从分类器中移除（减少到 ~160 类）比合并重复意图更有效，因为：
1. 减少类数 → 直接降低分类难度
2. 这些类的训练样本可能与业务类产生混淆

### 4.2 训练/测试数据分布偏差

分析师正确指出 80.5% 的样本 < 10 字符，但遗漏了一个更深层的问题：**train 和 val 来自同一分布**（90/10 random split）。这意味着：

- 当前 89.71% 的 F1 可能是**过度乐观的**，因为测试集也是 80% 短文本
- 如果用真实用户输入（平均 15-25 字符）做测试，F1 可能显著更低
- 数据增强改善的是模型泛化能力，但在当前 val set 上可能体现不出来

**建议**: 在优化之前，先构建一个**真实分布的 held-out 测试集**（50-100 条，从 E2E 测试中提取）。否则所有优化都在 "自己考自己" 上打转。

### 4.3 早停策略过于保守

当前训练使用 `EarlyStoppingCallback(early_stopping_patience=2)`，仅 5 个 epoch。在 177 类分类任务中，2 个 epoch 的 patience 太短 — 模型可能还没从初始下降中恢复就被停止了。分析师建议增加到 8 epochs + patience=3，这是合理的，但应该进一步考虑将 patience 增加到 4-5。

### 4.4 EQUIVALENT_INTENTS 机制已存在但未被利用

代码中 `IntentKnowledgeBase.java` 已有 `EQUIVALENT_INTENTS` 机制，将功能等价的意图分组。这意味着在 E2E 评估中，如果分类器预测了同组内的另一个意图，应该算作 "正确"。分析师在计算 "F1 可提升空间" 时没有考虑这一点 — 如果将等价组纳入评估，实际有效 F1 可能已经超过 92%。

---

## 五、实施时间线评估

### 分析师时间线 vs 实际预估

| Phase | 分析师预估 | Critic 评估 | 理由 |
|-------|-----------|-------------|------|
| Phase 1 | 2-3 天 | **3-5 天** | 未计入: (1) 同步 label_mapping 到 170 类基线 (2) 验证短语映射不含旧标签 (3) 手动审核 340 条非合并冲突 (4) 重新训练+ONNX导出+部署回归测试 |
| Phase 2 | 5-7 天 | **7-10 天** | 数据增强质量控制需要人工审核，LLM 回译成本和延迟被低估，Optuna 30 trials 在无 GPU 环境下耗时可能数天 |
| Phase 3 | 1-2 周 | **2-3 周** | 领域预训练需要先收集语料，分层分类需要完整重新设计推理管线 |

### GPU 资源假设

分析师未明确说明训练环境。根据 memory 中的记录，上一次训练用时 6.1 分钟（可能是 GPU 环境），但 Optuna 30 trials 意味着 ~3 小时训练时间。如果只有 CPU，时间可能膨胀 10-20 倍。

---

## 六、修订建议

### 推荐的实施优先级（调整后）

```
第 1 步（前提条件，0.5 天）:
  └── 将 label_mapping.json 同步到 170 类（与生产模型一致）

第 2 步（数据清洗，2-3 天，预计 +0.5~1.5%）:
  ├── 合并剩余 6-7 个重复类（170→163）
  ├── 删除无关意图类（NAVIGATE_*, MEDIA_*, SHOPPING_CART 等）→ ~155 类
  ├── 删除极端冲突样本（>3 标签的文本直接移除）
  └── 重新训练 + ONNX 导出 + 回归测试

第 3 步（数据质量提升，3-5 天，预计额外 +1.0~2.0%）:
  ├── 长句数据增强（最有价值的优化）
  ├── Label Smoothing + Epochs 调整
  └── 构建真实分布测试集（50-100 条）

第 4 步（条件执行，仅在第3步后 F1 < 92% 时，1-2 周）:
  ├── 领域预训练
  ├── Focal Loss / 超参搜索
  └── 置信度校准
```

### 核心 KPI 修订

| 指标 | 当前值 | 现实目标 | 分析师目标 |
|------|--------|----------|-----------|
| 分类器 F1 (val set) | 89.71% | 91.5-92.5% | 92-95% |
| E2E 路由准确率 | 97% | 98% | 93-96% (!) |
| LLM Fallback 率 | ~15-20% | <10% | <3% |

注意：分析师的 E2E 目标 (93-96%) 竟然**低于**当前已达到的 97%，这说明分析师在写报告时没有核实 E2E 数据。

---

## 七、总结

### 报告的优点
1. 数据质量问题诊断准确（冲突标签、短文本偏差）
2. 优化方向分类合理（Quick Win / Strategic / Nice-to-Have）
3. 风险评估框架完善
4. 数据增强建议（长句生成）是最有价值的建议

### 报告的主要问题
1. **短语映射数量错误 15 倍** — 从 "~200" vs 实际 2,954，严重影响对系统架构的理解
2. **生产模型基线混淆** — 177 类 vs 170 类不分，导致合并方案包含已完成的项目
3. **F1 增益叠加过度乐观** — 总计预估 +8~11%，现实应为 +2~4%
4. **完全忽略 E2E 97% 的现实** — 端到端准确率已远超分类器 F1 暗示的水平
5. **实施时间线低估** — 未考虑配置同步、回归测试、GPU 资源等实际开销
6. **缺乏对等价意图组机制的认识** — 已有 EQUIVALENT_INTENTS 可能使有效 F1 更高

### 核心建议
**不要追求分类器 F1 到 95%+ 的不切实际目标。当前系统端到端已达 97%，应以降低 LLM Fallback 率和减少延迟为主要优化方向，分类器 F1 提升到 91.5-92.5% 即可收获绝大部分实际收益。**

---

## 并行工作建议

### Subagent 并行: ✅ 推荐
- 数据清洗脚本 + 真实测试集构建（独立数据操作）
- Label Smoothing 实验 + 短语映射审计（前后端独立）

### 多Chat窗口并行: ⚠️ 有限推荐
- Python 训练脚本修改 + Java 路由审计（无冲突，但需要最后同步验证）
- 不建议同时修改 label_mapping.json 和 IntentKnowledgeBase.java（强依赖关系）

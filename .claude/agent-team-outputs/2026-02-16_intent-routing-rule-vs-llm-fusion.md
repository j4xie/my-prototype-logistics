# 意图路由架构：规则补丁 vs LLM融合方案 — Agent Team 综合报告

**日期**: 2026-02-16
**模式**: Full (3 Researchers + Analyst + Critic + Integrator)

---

## 执行摘要

当前意图路由系统（5层级联）在170个意图下表现尚可（F1 ~90%），但核心问题是：IntentKnowledgeBase 5860行硬编码规则已不可维护，每次修复需改3-4个文件，且规则间存在互斥冲突。三组研究一致认为纯规则补丁不可持续，但对LLM融合的深度和时机存在根本分歧。

**结论：先建可观测性基础设施（1周），再实施"置信度感知的LLM消歧层"（3-4周），最终视数据决定是否演进到每请求LLM参与的投票架构。**

---

## 共识与分歧

### 全员共识（高置信度）

| 共识点 | 置信度 |
|--------|--------|
| 纯规则补丁不可持续 — 5860行知识库、4处重复冲突检测 | **95%** |
| 端到端LLM替代不可行 — 170意图下准确率41-83%，成本过高 | **95%** |
| 级联架构是正确方向 — LangChain、Rasa 3.0、Anthropic均推荐 | **92%** |
| 语义缓存对工厂场景高价值 — 60%重复FAQ | **88%** |
| ONNX训练数据偏斜 — 80%工厂操作样本，食品知识严重不足 | **90%** |
| 预处理器存在语义破坏问题 | **90%** |

### 关键分歧

| 分歧点 | 分析师 | 批评家 | 最终判断 |
|--------|--------|--------|----------|
| 实际歧义率 | 10-15% | 20-35% | **15-25%，需实际数据验证** |
| LLM消歧准确率 | 92-95% | 80-88% | **85-92%（优化prompt后）** |
| 是否删除冲突检测 | 删除4处 | 绝不删除 | **不删除，但重构为统一入口** |
| 方案B是否算"融合" | 是 | 不是 | **是第一步，但不是终局** |
| 实施周期 | 3周 | 6-8周 | **4-5周** |

---

## 三种架构层级对比

```
层级1: 后置消歧（推荐先做）
短语/ONNX → 歧义检测(置信度<δ?) → LLM消歧(10-25%)
延迟: 平均15ms (75-90%不走LLM) / 成本: 30-80元/月

层级2: 并行投票（真正的融合，视数据决定）
短语/ONNX ─┐
            ├→ 投票决策器(加权融合) → 最终意图
LLM领域分类 ─┘
延迟: 平均80-150ms / 成本: 150-300元/月
LLM做领域分类(8大类)，不做170意图细分

层级3: LLM原生路由（不推荐）
LLM(170意图+用户历史+CoT) → 意图+槽位
延迟: 500-2000ms / 成本: 500-1500元/月
170意图时准确率反而下降
```

**推荐路径**: 层级1(4-5周) → 收集数据(2-4周) → 评估是否需要层级2
- 歧义率<15%: 停在层级1，优化ONNX训练数据
- 歧义率>25%: 演进到层级2

---

## 可执行建议

### 立即行动（本周）

| 编号 | 行动 | 工时 |
|------|------|------|
| I-1 | **埋点可观测性** — 每层出口记录：输入文本、匹配层级、置信度、top-3候选、最终意图 | 4h |
| I-2 | **歧义率基线统计** — 定义歧义信号，统计1周流量 | 2h |
| I-3 | **修复预处理器语义破坏** — 食品相关查询保留完整语义 | 3h |
| I-4 | **统一冲突检测入口** — 4处重复→ConflictDetector.java单一类 | 4h |

### 短期行动（2-4周）

| 编号 | 行动 | 依赖 |
|------|------|------|
| S-1 | **DisambiguationService** — ONNX分类后、最终决策前插入。触发条件：歧义信号任2个满足 | I-1/I-2 |
| S-2 | **语义缓存层** — cosine>0.95，缓存key含用户角色+时间粒度 | S-1 |
| S-3 | **ONNX训练数据补充** — 食品知识从<5%提到15-20% | 可并行 |
| S-4 | **A/B测试** — 10%流量走新路径，对比准确率和延迟 | S-1 |

### 条件行动

| 条件 | 行动 |
|------|------|
| 歧义率>25% | 升级到层级2（并行投票） |
| 消歧准确率<85% | 优化prompt + few-shot示例 |
| 月成本>100元 | 加强缓存，提高命中率到70%+ |

---

## 关键风险

| 风险 | 概率 | 缓解 |
|------|------|------|
| 歧义率远高于预期(>30%) | 中 | 语义缓存 + 监控告警 |
| LLM消歧引入新误判 | 中 | A/B测试 + 回滚开关 |
| 语义缓存误命中 | 中 | 缓存key含角色+时间+严格阈值 |
| 重构引入回归bug | 低 | I-4先于S-1，充分测试 |

---

## 批评家核心洞察

1. **不应删除冲突检测代码** — 这些是确定性安全网(hard gate)，LLM只处理灰色地带
2. **现有tryLlmFallback未解决问题即为反证** — 说明简单LLM调用不够，需要优化上下文
3. **方案B是"后置修补"不是"融合"** — 真正的融合=每次请求LLM都参与
4. **200行估计严重偏低** — 实际600-1000行，28个依赖注入的Service集成复杂
5. **层级2的关键设计**: LLM做领域分类(8大类)而非170意图，准确率>95%且延迟可控

---

## 待真实数据回答的问题

1. 实际歧义率是多少？（需1周生产流量数据）
2. 高频混淆意图对有哪些？（ONNX top-1 vs top-2频率表）
3. 食品知识查询占总流量比例？
4. tryLlmFallback当前成功率？
5. Qwen-long在食品vs工厂消歧上的实际表现？（需100条标注样本评测）

---

### Process Note
- Mode: Full
- Researchers deployed: 3
- Total sources found: 20+
- Key disagreements: 5 identified, 0 fully resolved (需数据验证)
- Phases completed: Research → Analysis → Critique → Integration

# 食品加工厂知识库训练 — 基准模型选择研究报告

**研究日期**: 2026-02-11
**研究模式**: Full (5 agents)
**研究员**: 3 | 分析师: 1 | 批评者: 1 | 整合者: 1

---

## Executive Summary

- **核心建议**: 采用"RoBERTa编码器(主力) + 食品领域自适应预训练(必要) + RAG+LLM(中期) + ONNX优化(长期)"四层架构
- **置信度**: **中等偏低** — Critic 合理质疑RoBERTa增量训练缺乏领域适应，食品NER跨域迁移灾难性遗忘风险高
- **关键风险**: (1)标注数据短缺(HIGH) (2)RoBERTa增量训练失败 (3)RAG法规更新陈旧引发法律风险 (4)服务器资源约束(8C/16GB无GPU)
- **时间影响**: Phase 1 需延长至2-3月(含领域预训练) → 总体延期4-6周
- **工作量**: 800-1200工程人时(含标注、模型训练、RAG工程、A/B灰度测试)

---

## 1. Consensus & Disagreements

| 主题 | 研究员 | 分析师 | 批评者 | 最终裁定 |
|------|--------|--------|--------|---------|
| **基础模型选型** | FoodBERT领域预训练提升5% F1 | 保持RoBERTa增量扩展 | RoBERTa跨域迁移风险高,需领域自适应 | **采纳批评——Phase1必须包含食品领域自适应预训练** |
| **LLM方案** | Qwen-7B QLoRA可在12GB VRAM运行 | 本地Qwen-7B不可行(资源不足) | (无新意见) | **仅用Qwen API,本地LLM不必要** |
| **RAG价值** | RAG适合高频更新知识(法规) | RAG+LLM中期最优投资 | RAG工程难度被低估,安全领域提升有限 | **RAG在合规检索有价值,但需强化版本控制/审计** |
| **蒸馏策略** | DistilBERT保留97%能力 | 3-6月蒸馏优化 | 蒸馏稳定性低,长尾类性能衰减严重 | **降低优先级——改用ONNX Runtime为首选** |
| **标注成本** | AgCNER 66,553样本可用 | 中概率风险 | 食品NER需专家,成本3-5倍,应为HIGH | **标注风险升级为HIGH/CRITICAL** |
| **服务器资源** | — | 隐含资源充足 | 16GB无GPU不可行 | **需云端GPU方案** |

---

## 2. Comparison Matrix

| 评估维度 | BERT/RoBERTa 微调 | MacBERT/LERT | Qwen API | RAG + LLM 混合 | 权重 |
|----------|-------------------|-------------|----------|---------------|------|
| **推理延迟** | 21-35ms(CPU) | 34-65ms(CPU) | 500-2000ms(API) | 检索50ms + API 500-2000ms | 高 |
| **部署内存** | ~400MB(base) | ~400MB(base) | 0(云端) | 400MB + 向量索引~200MB | 高 |
| **食品知识覆盖** | 需标注训练数据 | 同左 | 通用知识+提示工程 | 可动态扩展知识库 | 高 |
| **实施成本** | 3-5天(已有基础设施) | 5-7天 | 0天(已在用) | 10-15天 | 高 |
| **知识更新频率** | 需重新训练(天级) | 同左 | 实时(提示工程) | 实时(文档入库即生效) | 中 |
| **服务器适配(8C/16GB)** | 完全适配 | 完全适配 | 完全适配(云端) | 完全适配 | 高 |
| **训练数据需求** | 2000-5000条/类 | 同左 | 无需训练 | 需准备知识文档 | 中 |
| **生产稳定性** | 高(无外部依赖) | 高 | 中(依赖API可用性) | 中高 | 高 |

---

## 3. 食品领域可用模型与数据集

### 预训练模型
| 模型 | 类型 | 语言 | 特点 | 获取方式 |
|------|------|------|------|---------|
| FoodBERT | Domain BERT | 英文 | 食品分类+5% F1, NER | HuggingFace |
| AgBERT | Domain BERT | 中文 | 农业NER, 13类实体 | GitHub |
| chinese-roberta-wwm-ext | 通用BERT | 中文 | 93.12% Accuracy | HuggingFace |
| MacBERT | 通用BERT | 中文 | 同义词替换,适合领域术语 | GitHub |
| ModernBERT | 最新BERT | 英文 | SemEval-2025食品安全0.7952 | HuggingFace |

### 数据集
| 数据集 | 规模 | 语言 | 标注质量 | 获取难度 |
|--------|------|------|----------|---------|
| AgCNER | 66,553样本/206,992实体 | 中文 | ★★★★★ | 易(GitHub) |
| XiaChuFang | 152万食谱 | 中文 | ★★★★☆ | 易(OpenDataLab) |
| FoodBase | 12,844实体标注 | 英文 | ★★★★★ | 易(Oxford) |
| Recipe1M+ | 100万+食谱+1300万图片 | 英文 | ★★★★☆ | 中等(需申请) |
| FoodEarth | 81万+食品QA对 | 英文 | ★★★★☆ | 需联系作者 |
| OwnThink | 14亿三元组 | 中文 | ★★★☆☆ | 易(GitHub) |

---

## 4. 推荐方案: 修正版四阶段路线图

### Phase 1a: 领域自适应预训练 (Week 1-6, 并行)
- 收集5-10万食品工厂文本(工艺规程、检测报告、溯源日志、GB标准)
- RoBERTa权重初始化 → 食品语料继续预训练(Masked LM)
- GPU: 40小时A100 ≈ 5000-8000 RMB
- 预期: F1提升3-8%

### Phase 1b: 高质量标注集构建 (Week 3-7, 并行)
- 目标: 3000-5000高质量食品NER样本(13类)
- 人力: 2名领域专家(食品检验员背景)
- 工具: Doccano/Label Studio
- 质控: Cohen's Kappa>0.8

### Phase 1c: NER微调 + ONNX优化 (Week 7-8)
- 微调: 预训练后的RoBERTa → 食品NER + 意图扩展
- ONNX: 模型转换,推理延迟-15%,内存-20%
- 部署: 基准测试 + 上线

### Phase 2: RAG知识检索系统 (Month 3-5)
- 食品法规向量化 + pgvector存储
- 版本控制: 每条知识记录发布/过期日期
- 审计日志: 推荐理由链 + 人工审核触发
- A/B灰度测试

### Phase 3: 持续优化 (Month 6+)
- INT8量化(推理+10-20%提速)
- Active Learning数据飞轮(模型预测→专家验证→训练集)
- 评估蒸馏ROI(仅长尾类F1<70%时启动)

---

## 5. 核心结论: BERT vs RoBERTa vs LLM

### 最终答案

**不是"选一个"，而是"组合使用"：**

| 任务类型 | 推荐模型 | 原因 |
|---------|---------|------|
| **高频意图分类/NER** | RoBERTa-wwm-ext + 食品领域预训练 | 推理1-35ms, CPU可部署, 无API依赖 |
| **复杂推理/报告生成** | Qwen API (云端) | 8C/16GB无法本地LLM, API延迟可接受 |
| **知识检索/法规查询** | RAG (pgvector + Qwen) | 知识实时更新, 无需重训模型 |
| **生产线实时质检** | 未来: ONNX RoBERTa | 1-2ms延迟, CPU部署 |

### 为什么不选纯LLM?
1. 推理速度差23倍(277 vs 12样本/秒)
2. 8C/16GB无法本地运行7B+模型
3. API依赖=单点故障
4. 食品分类任务BERT≈GPT(研究证实)

### 为什么不选纯BERT?
1. 无法生成自然语言回答
2. 知识更新需重训(vs RAG实时更新)
3. 开放域问答能力弱

### 为什么必须做领域预训练?
1. FoodBERT证明: 领域预训练提升5% F1
2. 通用RoBERTa对食品术语("杀菌釜"/"水分活度Aw"/"GB 2760")语义表示不足
3. 不做预训练→增量训练触发灾难性遗忘→原有意图F1下降5-15%

---

## 6. Risk Assessment

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|---------|
| 标注数据短缺 | **HIGH(70%)** | 致命 | 利用AgCNER+众包+Active Learning |
| 灾难性遗忘 | **HIGH(55%)** | 高 | 领域自适应预训练+EWC增量学习 |
| RAG法规幻觉 | **中(40%)** | 致命 | 版本控制+审计日志+人工抽检 |
| 服务器OOM | **HIGH(60%)** | 致命 | ONNX优化+内存监控+升级方案 |
| API成本失控 | **中(45%)** | 中 | 监控+DeepSeek备用+限流 |
| 配置膨胀 | **中(50%)** | 中 | 自动化配置管理+回归测试 |

---

## 7. Confidence Assessment

| 结论 | 置信度 | 依据 |
|------|--------|------|
| RoBERTa需食品领域自适应预训练 | ★★★★★ | FoodBERT铁证+跨域迁移理论 |
| 混合架构(BERT高频+LLM低频)正确 | ★★★★☆ | 3 agents共识 |
| 本地Qwen-7B不可行 | ★★★★★ | 硬件约束客观 |
| RAG中期价值显著但风险中等 | ★★★☆☆ | 需A/B灰度验证 |
| 标注数据风险为HIGH | ★★★★☆ | 食品NER成本3-5倍有先例 |
| ONNX Runtime优于蒸馏 | ★★★☆☆ | 工程实践判断,缺一手数据 |

---

## 8. Open Questions

1. 食品领域文本来源——现有客户能提供多少脱敏工艺文本?
2. 标注专家可用性——食品检验员兼职标注是否可行?
3. LLM API月度成本预估——Qwen API日均调用量?
4. RAG知识版本管理系统——是否已有?如无需先建(1-2月)
5. 端到端延迟SLA——实时建议<500ms vs 后台批处理<30s?
6. 中文食品术语分词——RoBERTa WordPiece对"己二酸钠"等专有名词切割准确率?
7. GPU租赁方案——阿里云GPU实例可用性和价格?

---

### Process Note
- Mode: Full
- Researchers deployed: 3
- Total sources found: 40+
- Key disagreements: 6 resolved, 1 unresolved (RAG safety性能上界)
- Phases completed: Research → Analysis → Critique → Integration
